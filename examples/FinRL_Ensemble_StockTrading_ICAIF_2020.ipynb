{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lb9q2_QZgdNk"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/AI4Finance-Foundation/FinRL-Tutorials/blob/master/2-Advance/FinRL_Ensemble_StockTrading_ICAIF_2020.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXaoZs2lh1hi"
      },
      "source": [
        "# Deep Reinforcement Learning for Stock Trading from Scratch: Multiple Stock Trading Using Ensemble Strategy\n",
        "\n",
        "Tutorials to use OpenAI DRL to trade multiple stocks using ensemble strategy in one Jupyter Notebook | Presented at ICAIF 2020\n",
        "\n",
        "* This notebook is the reimplementation of our paper: Deep Reinforcement Learning for Automated Stock Trading: An Ensemble Strategy, using FinRL.\n",
        "* Check out medium blog for detailed explanations: https://medium.com/@ai4finance/deep-reinforcement-learning-for-automated-stock-trading-f1dad0126a02\n",
        "* Please report any issues to our Github: https://github.com/AI4Finance-LLC/FinRL-Library/issues\n",
        "* **Pytorch Version**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGunVt8oLCVS"
      },
      "source": [
        "# Content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOzAKQ-SLGX6"
      },
      "source": [
        "* [1. Problem Definition](#0)\n",
        "* [2. Getting Started - Load Python packages](#1)\n",
        "    * [2.1. Install Packages](#1.1)    \n",
        "    * [2.2. Check Additional Packages](#1.2)\n",
        "    * [2.3. Import Packages](#1.3)\n",
        "    * [2.4. Create Folders](#1.4)\n",
        "* [3. Download Data](#2)\n",
        "* [4. Preprocess Data](#3)        \n",
        "    * [4.1. Technical Indicators](#3.1)\n",
        "    * [4.2. Perform Feature Engineering](#3.2)\n",
        "* [5.Build Environment](#4)  \n",
        "    * [5.1. Training & Trade Data Split](#4.1)\n",
        "    * [5.2. User-defined Environment](#4.2)   \n",
        "    * [5.3. Initialize Environment](#4.3)    \n",
        "* [6.Implement DRL Algorithms](#5)  \n",
        "* [7.Backtesting Performance](#6)  \n",
        "    * [7.1. BackTestStats](#6.1)\n",
        "    * [7.2. BackTestPlot](#6.2)   \n",
        "    * [7.3. Baseline Stats](#6.3)   \n",
        "    * [7.3. Compare to Stock Market Index](#6.4)             "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sApkDlD9LIZv"
      },
      "source": [
        "<a id='0'></a>\n",
        "# Part 1. Problem Definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjLD2TZSLKZ-"
      },
      "source": [
        "This problem is to design an automated trading solution for single stock trading. We model the stock trading process as a Markov Decision Process (MDP). We then formulate our trading goal as a maximization problem.\n",
        "\n",
        "The algorithm is trained using Deep Reinforcement Learning (DRL) algorithms and the components of the reinforcement learning environment are:\n",
        "\n",
        "\n",
        "* Action: The action space describes the allowed actions that the agent interacts with the\n",
        "environment. Normally, a ∈ A includes three actions: a ∈ {−1, 0, 1}, where −1, 0, 1 represent\n",
        "selling, holding, and buying one stock. Also, an action can be carried upon multiple shares. We use\n",
        "an action space {−k, ..., −1, 0, 1, ..., k}, where k denotes the number of shares. For example, \"Buy\n",
        "10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or −10, respectively\n",
        "\n",
        "* Reward function: r(s, a, s′) is the incentive mechanism for an agent to learn a better action. The change of the portfolio value when action a is taken at state s and arriving at new state s',  i.e., r(s, a, s′) = v′ − v, where v′ and v represent the portfolio\n",
        "values at state s′ and s, respectively\n",
        "\n",
        "* State: The state space describes the observations that the agent receives from the environment. Just as a human trader needs to analyze various information before executing a trade, so\n",
        "our trading agent observes many different features to better learn in an interactive environment.\n",
        "\n",
        "* Environment: Dow 30 consituents\n",
        "\n",
        "\n",
        "The data of the single stock that we will be using for this case study is obtained from Yahoo Finance API. The data contains Open-High-Low-Close price and volume.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ffsre789LY08"
      },
      "source": [
        "<a id='1'></a>\n",
        "# Part 2. Getting Started- Load Python Packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uy5_PTmOh1hj"
      },
      "source": [
        "<a id='1.1'></a>\n",
        "## 2.1. Install all the packages through FinRL library\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mPT0ipYE28wL",
        "outputId": "e77804c3-98bd-41a3-e4f0-f28ba32e79a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wrds\n",
            "  Downloading wrds-3.3.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: packaging<=24.2 in /usr/local/lib/python3.11/dist-packages (from wrds) (24.2)\n",
            "Requirement already satisfied: pandas<2.3,>=2.2 in /usr/local/lib/python3.11/dist-packages (from wrds) (2.2.2)\n",
            "Collecting psycopg2-binary<2.10,>=2.9 (from wrds)\n",
            "  Downloading psycopg2_binary-2.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: sqlalchemy<2.1,>=2 in /usr/local/lib/python3.11/dist-packages (from wrds) (2.0.40)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3,>=2.2->wrds) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3,>=2.2->wrds) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3,>=2.2->wrds) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3,>=2.2->wrds) (2025.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<2.1,>=2->wrds) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<2.1,>=2->wrds) (4.13.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<2.3,>=2.2->wrds) (1.17.0)\n",
            "Downloading wrds-3.3.0-py3-none-any.whl (13 kB)\n",
            "Downloading psycopg2_binary-2.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: psycopg2-binary, wrds\n",
            "Successfully installed psycopg2-binary-2.9.10 wrds-3.3.0\n",
            "Collecting swig\n",
            "  Downloading swig-4.3.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (3.5 kB)\n",
            "Downloading swig-4.3.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: swig\n",
            "Successfully installed swig-4.3.0\n",
            "⏬ Downloading https://github.com/jaimergp/miniforge/releases/download/24.11.2-1_colab/Miniforge3-colab-24.11.2-1_colab-Linux-x86_64.sh...\n",
            "📦 Installing...\n",
            "📌 Adjusting configuration...\n",
            "🩹 Patching environment...\n",
            "⏲ Done in 0:00:17\n",
            "🔁 Restarting kernel...\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Selecting previously unselected package swig4.0.\n",
            "(Reading database ... 126315 files and directories currently installed.)\n",
            "Preparing to unpack .../swig4.0_4.0.2-1ubuntu1_amd64.deb ...\n",
            "Unpacking swig4.0 (4.0.2-1ubuntu1) ...\n",
            "Selecting previously unselected package swig.\n",
            "Preparing to unpack .../swig_4.0.2-1ubuntu1_all.deb ...\n",
            "Unpacking swig (4.0.2-1ubuntu1) ...\n",
            "Setting up swig4.0 (4.0.2-1ubuntu1) ...\n",
            "Setting up swig (4.0.2-1ubuntu1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting git+https://github.com/AI4Finance-Foundation/FinRL.git\n",
            "  Cloning https://github.com/AI4Finance-Foundation/FinRL.git to /tmp/pip-req-build-69rw30ee\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/AI4Finance-Foundation/FinRL.git /tmp/pip-req-build-69rw30ee\n",
            "  Resolved https://github.com/AI4Finance-Foundation/FinRL.git to commit d25d902a6de54931a329adc38a2663e8f576adc4\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git (from finrl==0.3.8)\n",
            "  Cloning https://github.com/AI4Finance-Foundation/ElegantRL.git to /tmp/pip-install-9dtgwws5/elegantrl_966e1faa774d41dbb7d11b704ad4639f\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/AI4Finance-Foundation/ElegantRL.git /tmp/pip-install-9dtgwws5/elegantrl_966e1faa774d41dbb7d11b704ad4639f\n",
            "  Resolved https://github.com/AI4Finance-Foundation/ElegantRL.git to commit 5e828af1503098f4da046c0f12432dbd4ef8bd97\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting alpaca-py<0.38,>=0.37 (from finrl==0.3.8)\n",
            "  Downloading alpaca_py-0.37.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting alpaca-trade-api<4,>=3 (from finrl==0.3.8)\n",
            "  Downloading alpaca_trade_api-3.2.0-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting ccxt<4,>=3 (from finrl==0.3.8)\n",
            "  Downloading ccxt-3.1.60-py2.py3-none-any.whl.metadata (108 kB)\n",
            "Collecting jqdatasdk<2,>=1 (from finrl==0.3.8)\n",
            "  Downloading jqdatasdk-1.9.7-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting pyfolio-reloaded<0.10,>=0.9 (from finrl==0.3.8)\n",
            "  Downloading pyfolio_reloaded-0.9.8-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting pyportfolioopt<2,>=1 (from finrl==0.3.8)\n",
            "  Downloading pyportfolioopt-1.5.6-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting ray<3,>=2 (from ray[default,tune]<3,>=2->finrl==0.3.8)\n",
            "  Downloading ray-2.44.1-cp311-cp311-manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Collecting scikit-learn<2,>=1 (from finrl==0.3.8)\n",
            "  Downloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting selenium<5,>=4 (from finrl==0.3.8)\n",
            "  Downloading selenium-4.31.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting stable-baselines3>=2.0.0a5 (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8)\n",
            "  Downloading stable_baselines3-2.6.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting stockstats<0.6,>=0.5 (from finrl==0.3.8)\n",
            "  Downloading stockstats-0.5.4-py2.py3-none-any.whl.metadata (26 kB)\n",
            "Collecting webdriver-manager<5,>=4 (from finrl==0.3.8)\n",
            "  Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting wrds<4,>=3 (from finrl==0.3.8)\n",
            "  Using cached wrds-3.3.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting yfinance<0.3,>=0.2 (from finrl==0.3.8)\n",
            "  Downloading yfinance-0.2.55-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting msgpack<2.0.0,>=1.0.3 (from alpaca-py<0.38,>=0.37->finrl==0.3.8)\n",
            "  Downloading msgpack-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
            "Collecting pandas>=1.5.3 (from alpaca-py<0.38,>=0.37->finrl==0.3.8)\n",
            "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "Collecting pydantic<3.0.0,>=2.0.3 (from alpaca-py<0.38,>=0.37->finrl==0.3.8)\n",
            "  Downloading pydantic-2.11.3-py3-none-any.whl.metadata (65 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.30.0 in /usr/local/lib/python3.11/site-packages (from alpaca-py<0.38,>=0.37->finrl==0.3.8) (2.32.3)\n",
            "Collecting sseclient-py<2.0.0,>=1.7.2 (from alpaca-py<0.38,>=0.37->finrl==0.3.8)\n",
            "  Downloading sseclient_py-1.8.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting websockets>=10.4 (from alpaca-py<0.38,>=0.37->finrl==0.3.8)\n",
            "  Downloading websockets-15.0.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting numpy>=1.11.1 (from alpaca-trade-api<4,>=3->finrl==0.3.8)\n",
            "  Downloading numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Collecting urllib3<2,>1.24 (from alpaca-trade-api<4,>=3->finrl==0.3.8)\n",
            "  Downloading urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n",
            "Collecting websocket-client<2,>=0.56.0 (from alpaca-trade-api<4,>=3->finrl==0.3.8)\n",
            "  Downloading websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting websockets>=10.4 (from alpaca-py<0.38,>=0.37->finrl==0.3.8)\n",
            "  Downloading websockets-10.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
            "Collecting msgpack<2.0.0,>=1.0.3 (from alpaca-py<0.38,>=0.37->finrl==0.3.8)\n",
            "  Downloading msgpack-1.0.3.tar.gz (123 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting aiohttp<4,>=3.8.3 (from alpaca-trade-api<4,>=3->finrl==0.3.8)\n",
            "  Downloading aiohttp-3.11.16-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting PyYAML==6.0.1 (from alpaca-trade-api<4,>=3->finrl==0.3.8)\n",
            "  Downloading PyYAML-6.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting deprecation==2.1.0 (from alpaca-trade-api<4,>=3->finrl==0.3.8)\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/site-packages (from deprecation==2.1.0->alpaca-trade-api<4,>=3->finrl==0.3.8) (24.2)\n",
            "Requirement already satisfied: setuptools>=60.9.0 in /usr/local/lib/python3.11/site-packages (from ccxt<4,>=3->finrl==0.3.8) (65.6.3)\n",
            "Requirement already satisfied: certifi>=2018.1.18 in /usr/local/lib/python3.11/site-packages (from ccxt<4,>=3->finrl==0.3.8) (2024.12.14)\n",
            "Collecting cryptography>=2.6.1 (from ccxt<4,>=3->finrl==0.3.8)\n",
            "  Downloading cryptography-44.0.2-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (5.7 kB)\n",
            "Collecting aiodns>=1.1.1 (from ccxt<4,>=3->finrl==0.3.8)\n",
            "  Downloading aiodns-3.2.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting yarl>=1.7.2 (from ccxt<4,>=3->finrl==0.3.8)\n",
            "  Downloading yarl-1.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (71 kB)\n",
            "Collecting six (from jqdatasdk<2,>=1->finrl==0.3.8)\n",
            "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting SQLAlchemy>=1.2.8 (from jqdatasdk<2,>=1->finrl==0.3.8)\n",
            "  Downloading sqlalchemy-2.0.40-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Collecting pymysql>=0.7.6 (from jqdatasdk<2,>=1->finrl==0.3.8)\n",
            "  Downloading PyMySQL-1.1.1-py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting thriftpy2!=0.5.1,>=0.3.9 (from jqdatasdk<2,>=1->finrl==0.3.8)\n",
            "  Downloading thriftpy2-0.5.2.tar.gz (782 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m782.3/782.3 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ipython>=3.2.3 (from pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8)\n",
            "  Downloading ipython-9.1.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting matplotlib>=1.4.0 (from pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8)\n",
            "  Downloading matplotlib-3.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting pytz>=2014.10 (from pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8)\n",
            "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting scipy>=0.14.0 (from pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8)\n",
            "  Downloading scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting seaborn>=0.7.1 (from pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8)\n",
            "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting empyrical-reloaded>=0.5.9 (from pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8)\n",
            "  Downloading empyrical_reloaded-0.5.11-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting cvxpy>=1.1.19 (from pyportfolioopt<2,>=1->finrl==0.3.8)\n",
            "  Downloading cvxpy-1.6.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
            "Collecting ecos<3.0.0,>=2.0.14 (from pyportfolioopt<2,>=1->finrl==0.3.8)\n",
            "  Downloading ecos-2.0.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.0 kB)\n",
            "Collecting plotly<6.0.0,>=5.0.0 (from pyportfolioopt<2,>=1->finrl==0.3.8)\n",
            "  Downloading plotly-5.24.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting click>=7.0 (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.8)\n",
            "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting filelock (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.8)\n",
            "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting jsonschema (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.8)\n",
            "  Downloading jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting protobuf!=3.19.5,>=3.15.3 (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.8)\n",
            "  Downloading protobuf-6.30.2-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
            "Collecting aiosignal (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.8)\n",
            "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting frozenlist (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.8)\n",
            "  Downloading frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting aiohttp_cors (from ray[default,tune]<3,>=2->finrl==0.3.8)\n",
            "  Downloading aiohttp_cors-0.8.1-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting colorful (from ray[default,tune]<3,>=2->finrl==0.3.8)\n",
            "  Downloading colorful-0.5.6-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Collecting py-spy>=0.2.0 (from ray[default,tune]<3,>=2->finrl==0.3.8)\n",
            "  Downloading py_spy-0.4.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (16 kB)\n",
            "Collecting grpcio>=1.42.0 (from ray[default,tune]<3,>=2->finrl==0.3.8)\n",
            "  Downloading grpcio-1.71.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting opencensus (from ray[default,tune]<3,>=2->finrl==0.3.8)\n",
            "  Downloading opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting prometheus_client>=0.7.1 (from ray[default,tune]<3,>=2->finrl==0.3.8)\n",
            "  Downloading prometheus_client-0.21.1-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting smart_open (from ray[default,tune]<3,>=2->finrl==0.3.8)\n",
            "  Downloading smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting virtualenv!=20.21.1,>=20.0.24 (from ray[default,tune]<3,>=2->finrl==0.3.8)\n",
            "  Downloading virtualenv-20.30.0-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting tensorboardX>=1.9 (from ray[default,tune]<3,>=2->finrl==0.3.8)\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting pyarrow>=9.0.0 (from ray[default,tune]<3,>=2->finrl==0.3.8)\n",
            "  Downloading pyarrow-19.0.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting fsspec (from ray[default,tune]<3,>=2->finrl==0.3.8)\n",
            "  Downloading fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting joblib>=1.2.0 (from scikit-learn<2,>=1->finrl==0.3.8)\n",
            "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit-learn<2,>=1->finrl==0.3.8)\n",
            "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting trio~=0.17 (from selenium<5,>=4->finrl==0.3.8)\n",
            "  Downloading trio-0.29.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting trio-websocket~=0.9 (from selenium<5,>=4->finrl==0.3.8)\n",
            "  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting typing_extensions~=4.9 (from selenium<5,>=4->finrl==0.3.8)\n",
            "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gymnasium<1.2.0,>=0.29.1 (from stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8)\n",
            "  Downloading gymnasium-1.1.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting torch<3.0,>=2.3 (from stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8)\n",
            "  Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Collecting cloudpickle (from stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8)\n",
            "  Downloading cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting opencv-python (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8)\n",
            "  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting pygame (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8)\n",
            "  Downloading pygame-2.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting tensorboard>=2.9.1 (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8)\n",
            "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting psutil (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8)\n",
            "  Downloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/site-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8) (4.67.1)\n",
            "Collecting rich (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8)\n",
            "  Downloading rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting ale-py>=0.9.0 (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8)\n",
            "  Downloading ale_py-0.10.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.2 kB)\n",
            "Collecting pillow (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8)\n",
            "  Downloading pillow-11.2.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
            "Collecting python-dotenv (from webdriver-manager<5,>=4->finrl==0.3.8)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting psycopg2-binary<2.10,>=2.9 (from wrds<4,>=3->finrl==0.3.8)\n",
            "  Using cached psycopg2_binary-2.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting multitasking>=0.0.7 (from yfinance<0.3,>=0.2->finrl==0.3.8)\n",
            "  Downloading multitasking-0.0.11-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.11/site-packages (from yfinance<0.3,>=0.2->finrl==0.3.8) (4.3.6)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.11/site-packages (from yfinance<0.3,>=0.2->finrl==0.3.8) (2.4.6)\n",
            "Collecting peewee>=3.16.2 (from yfinance<0.3,>=0.2->finrl==0.3.8)\n",
            "  Downloading peewee-3.17.9.tar.gz (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m91.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting beautifulsoup4>=4.11.1 (from yfinance<0.3,>=0.2->finrl==0.3.8)\n",
            "  Downloading beautifulsoup4-4.13.3-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting th (from elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git->finrl==0.3.8)\n",
            "  Downloading th-0.4.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting pycares>=4.0.0 (from aiodns>=1.1.1->ccxt<4,>=3->finrl==0.3.8)\n",
            "  Downloading pycares-4.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
            "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4,>=3.8.3->alpaca-trade-api<4,>=3->finrl==0.3.8)\n",
            "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting attrs>=17.3.0 (from aiohttp<4,>=3.8.3->alpaca-trade-api<4,>=3->finrl==0.3.8)\n",
            "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp<4,>=3.8.3->alpaca-trade-api<4,>=3->finrl==0.3.8)\n",
            "  Downloading multidict-6.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting propcache>=0.2.0 (from aiohttp<4,>=3.8.3->alpaca-trade-api<4,>=3->finrl==0.3.8)\n",
            "  Downloading propcache-0.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Collecting soupsieve>1.2 (from beautifulsoup4>=4.11.1->yfinance<0.3,>=0.2->finrl==0.3.8)\n",
            "  Downloading soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/site-packages (from cryptography>=2.6.1->ccxt<4,>=3->finrl==0.3.8) (1.17.1)\n",
            "Collecting osqp>=0.6.2 (from cvxpy>=1.1.19->pyportfolioopt<2,>=1->finrl==0.3.8)\n",
            "  Downloading osqp-1.0.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting clarabel>=0.5.0 (from cvxpy>=1.1.19->pyportfolioopt<2,>=1->finrl==0.3.8)\n",
            "  Downloading clarabel-0.10.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Collecting scs>=3.2.4.post1 (from cvxpy>=1.1.19->pyportfolioopt<2,>=1->finrl==0.3.8)\n",
            "  Downloading scs-3.2.7.post2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting bottleneck>=1.3.0 (from empyrical-reloaded>=0.5.9->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8)\n",
            "  Downloading Bottleneck-1.4.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting peewee>=3.16.2 (from yfinance<0.3,>=0.2->finrl==0.3.8)\n",
            "  Downloading peewee-3.17.3.tar.gz (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m92.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium<1.2.0,>=0.29.1->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
            "Collecting decorator (from ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8)\n",
            "  Downloading decorator-5.2.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting ipython-pygments-lexers (from ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8)\n",
            "  Downloading ipython_pygments_lexers-1.1.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting jedi>=0.16 (from ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting matplotlib-inline (from ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8)\n",
            "  Downloading matplotlib_inline-0.1.7-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting pexpect>4.3 (from ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8)\n",
            "  Downloading pexpect-4.9.0-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting prompt_toolkit<3.1.0,>=3.0.41 (from ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8)\n",
            "  Downloading prompt_toolkit-3.0.50-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting pygments>=2.4.0 (from ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8)\n",
            "  Downloading pygments-2.19.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting stack_data (from ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8)\n",
            "  Downloading stack_data-0.6.3-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting traitlets>=5.13.0 (from ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8)\n",
            "  Downloading traitlets-5.14.3-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib>=1.4.0->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8)\n",
            "  Downloading contourpy-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib>=1.4.0->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8)\n",
            "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib>=1.4.0->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8)\n",
            "  Downloading fonttools-4.57.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (102 kB)\n",
            "Collecting kiwisolver>=1.3.1 (from matplotlib>=1.4.0->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8)\n",
            "  Downloading kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
            "Collecting pyparsing>=2.3.1 (from matplotlib>=1.4.0->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8)\n",
            "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting python-dateutil>=2.7 (from matplotlib>=1.4.0->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8)\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas>=1.5.3->alpaca-py<0.38,>=0.37->finrl==0.3.8)\n",
            "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting tenacity>=6.2.0 (from plotly<6.0.0,>=5.0.0->pyportfolioopt<2,>=1->finrl==0.3.8)\n",
            "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.0.3->alpaca-py<0.38,>=0.37->finrl==0.3.8)\n",
            "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.33.1 (from pydantic<3.0.0,>=2.0.3->alpaca-py<0.38,>=0.37->finrl==0.3.8)\n",
            "  Downloading pydantic_core-2.33.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting typing-inspection>=0.4.0 (from pydantic<3.0.0,>=2.0.3->alpaca-py<0.38,>=0.37->finrl==0.3.8)\n",
            "  Downloading typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests<3.0.0,>=2.30.0->alpaca-py<0.38,>=0.37->finrl==0.3.8) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests<3.0.0,>=2.30.0->alpaca-py<0.38,>=0.37->finrl==0.3.8) (3.10)\n",
            "Collecting greenlet>=1 (from SQLAlchemy>=1.2.8->jqdatasdk<2,>=1->finrl==0.3.8)\n",
            "  Downloading greenlet-3.1.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting absl-py>=0.4 (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8)\n",
            "  Downloading absl_py-2.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting markdown>=2.6.8 (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8)\n",
            "  Downloading markdown-3.8-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8)\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8)\n",
            "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting Cython>=3.0.10 (from thriftpy2!=0.5.1,>=0.3.9->jqdatasdk<2,>=1->finrl==0.3.8)\n",
            "  Using cached Cython-3.0.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting ply<4.0,>=3.4 (from thriftpy2!=0.5.1,>=0.3.9->jqdatasdk<2,>=1->finrl==0.3.8)\n",
            "  Downloading ply-3.11-py2.py3-none-any.whl.metadata (844 bytes)\n",
            "Collecting networkx (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8)\n",
            "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jinja2 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8)\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8)\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8)\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8)\n",
            "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.2.0 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8)\n",
            "  Downloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Collecting sympy==1.13.1 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8)\n",
            "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8)\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting sortedcontainers (from trio~=0.17->selenium<5,>=4->finrl==0.3.8)\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Collecting outcome (from trio~=0.17->selenium<5,>=4->finrl==0.3.8)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting sniffio>=1.3.0 (from trio~=0.17->selenium<5,>=4->finrl==0.3.8)\n",
            "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium<5,>=4->finrl==0.3.8)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/site-packages (from urllib3[socks]<3,>=1.26->selenium<5,>=4->finrl==0.3.8) (1.7.1)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<3,>=2->finrl==0.3.8)\n",
            "  Downloading distlib-0.3.9-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema->ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.8)\n",
            "  Downloading jsonschema_specifications-2024.10.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting referencing>=0.28.4 (from jsonschema->ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.8)\n",
            "  Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting rpds-py>=0.7.1 (from jsonschema->ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.8)\n",
            "  Downloading rpds_py-0.24.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting opencensus-context>=0.1.3 (from opencensus->ray[default,tune]<3,>=2->finrl==0.3.8)\n",
            "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting google-api-core<3.0.0,>=1.0.0 (from opencensus->ray[default,tune]<3,>=2->finrl==0.3.8)\n",
            "  Downloading google_api_core-2.24.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8)\n",
            "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting wrapt (from smart_open->ray[default,tune]<3,>=2->finrl==0.3.8)\n",
            "  Downloading wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
            "Collecting niltype<2.0,>=0.3 (from th->elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git->finrl==0.3.8)\n",
            "  Downloading niltype-1.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/site-packages (from cffi>=1.12->cryptography>=2.6.1->ccxt<4,>=3->finrl==0.3.8) (2.22)\n",
            "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.8)\n",
            "  Downloading googleapis_common_protos-1.69.2-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting proto-plus<2.0.0,>=1.22.3 (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.8)\n",
            "  Downloading proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting google-auth<3.0.0,>=2.14.1 (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.8)\n",
            "  Downloading google_auth-2.38.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting parso<0.9.0,>=0.8.4 (from jedi>=0.16->ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8)\n",
            "  Downloading parso-0.8.4-py2.py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8)\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting ptyprocess>=0.5 (from pexpect>4.3->ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8)\n",
            "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting wcwidth (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8)\n",
            "  Downloading wcwidth-0.2.13-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.8)\n",
            "  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.9->selenium<5,>=4->finrl==0.3.8)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting executing>=1.2.0 (from stack_data->ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8)\n",
            "  Downloading executing-2.2.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting asttokens>=2.1.0 (from stack_data->ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8)\n",
            "  Downloading asttokens-3.0.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting pure-eval (from stack_data->ipython>=3.2.3->pyfolio-reloaded<0.10,>=0.9->finrl==0.3.8)\n",
            "  Downloading pure_eval-0.2.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.8)\n",
            "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.8)\n",
            "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting rsa<5,>=3.1.4 (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.8)\n",
            "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting pyasn1<0.7.0,>=0.6.1 (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.8)\n",
            "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
            "Downloading alpaca_py-0.37.0-py3-none-any.whl (121 kB)\n",
            "Downloading alpaca_trade_api-3.2.0-py3-none-any.whl (34 kB)\n",
            "Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading PyYAML-6.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (757 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m757.7/757.7 kB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ccxt-3.1.60-py2.py3-none-any.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m120.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jqdatasdk-1.9.7-py3-none-any.whl (77 kB)\n",
            "Downloading pyfolio_reloaded-0.9.8-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m139.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyportfolioopt-1.5.6-py3-none-any.whl (62 kB)\n",
            "Downloading ray-2.44.1-cp311-cp311-manylinux2014_x86_64.whl (68.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.1/68.1 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m156.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading selenium-4.31.0-py3-none-any.whl (9.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m139.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stable_baselines3-2.6.0-py3-none-any.whl (184 kB)\n",
            "Downloading stockstats-0.5.4-py2.py3-none-any.whl (21 kB)\n",
            "Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n",
            "Using cached wrds-3.3.0-py3-none-any.whl (13 kB)\n",
            "Downloading yfinance-0.2.55-py2.py3-none-any.whl (109 kB)\n",
            "Downloading aiodns-3.2.0-py3-none-any.whl (5.7 kB)\n",
            "Downloading aiohttp-3.11.16-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m84.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading ale_py-0.10.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m98.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading beautifulsoup4-4.13.3-py3-none-any.whl (186 kB)\n",
            "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
            "Downloading cryptography-44.0.2-cp39-abi3-manylinux_2_34_x86_64.whl (4.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m130.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cvxpy-1.6.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ecos-2.0.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (220 kB)\n",
            "Downloading empyrical_reloaded-0.5.11-py3-none-any.whl (32 kB)\n",
            "Downloading frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (274 kB)\n",
            "Downloading grpcio-1.71.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m150.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gymnasium-1.1.1-py3-none-any.whl (965 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m965.4/965.4 kB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading ipython-9.1.0-py3-none-any.whl (604 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m604.1/604.1 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "Downloading matplotlib-3.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m148.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multitasking-0.0.11-py3-none-any.whl (8.5 kB)\n",
            "Downloading numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m167.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m167.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-11.2.1-cp311-cp311-manylinux_2_28_x86_64.whl (4.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m137.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading plotly-5.24.1-py3-none-any.whl (19.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading prometheus_client-0.21.1-py3-none-any.whl (54 kB)\n",
            "Downloading protobuf-6.30.2-cp39-abi3-manylinux2014_x86_64.whl (316 kB)\n",
            "Using cached psycopg2_binary-2.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "Downloading py_spy-0.4.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m113.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-19.0.1-cp311-cp311-manylinux_2_28_x86_64.whl (42.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.11.3-py3-none-any.whl (443 kB)\n",
            "Downloading pydantic_core-2.33.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m96.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyMySQL-1.1.1-py3-none-any.whl (44 kB)\n",
            "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "Downloading scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.6/37.6 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
            "Downloading sqlalchemy-2.0.40-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m127.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sseclient_py-1.8.0-py2.py3-none-any.whl (8.8 kB)\n",
            "Downloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m141.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
            "Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl (766.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m93.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m78.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m85.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m65.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m70.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m143.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.2/253.2 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio-0.29.0-py3-none-any.whl (492 kB)\n",
            "Downloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
            "Downloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
            "Downloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
            "Downloading virtualenv-20.30.0-py3-none-any.whl (4.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m135.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
            "Downloading websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
            "Downloading websockets-10.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (107 kB)\n",
            "Downloading yarl-1.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (358 kB)\n",
            "Downloading aiohttp_cors-0.8.1-py3-none-any.whl (25 kB)\n",
            "Downloading colorful-0.5.6-py2.py3-none-any.whl (201 kB)\n",
            "Downloading fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
            "Downloading jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
            "Downloading opencensus-0.11.4-py2.py3-none-any.whl (128 kB)\n",
            "Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (277 kB)\n",
            "Downloading pygame-2.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m144.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
            "Downloading smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
            "Downloading th-0.4.1-py3-none-any.whl (12 kB)\n",
            "Downloading absl_py-2.2.2-py3-none-any.whl (135 kB)\n",
            "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
            "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
            "Downloading Bottleneck-1.4.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (360 kB)\n",
            "Downloading clarabel-0.10.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading contourpy-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)\n",
            "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Using cached Cython-3.0.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "Downloading distlib-0.3.9-py2.py3-none-any.whl (468 kB)\n",
            "Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Downloading fonttools-4.57.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m146.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_api_core-2.24.2-py3-none-any.whl (160 kB)\n",
            "Downloading greenlet-3.1.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (602 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m602.4/602.4 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonschema_specifications-2024.10.1-py3-none-any.whl (18 kB)\n",
            "Downloading kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading markdown-3.8-py3-none-any.whl (106 kB)\n",
            "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "Downloading multidict-6.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (223 kB)\n",
            "Downloading niltype-1.0.2-py3-none-any.whl (5.3 kB)\n",
            "Downloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
            "Downloading osqp-1.0.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (344 kB)\n",
            "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading pexpect-4.9.0-py2.py3-none-any.whl (63 kB)\n",
            "Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
            "Downloading prompt_toolkit-3.0.50-py3-none-any.whl (387 kB)\n",
            "Downloading propcache-0.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (232 kB)\n",
            "Downloading pycares-4.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (289 kB)\n",
            "Downloading pygments-2.19.1-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
            "Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "Downloading referencing-0.36.2-py3-none-any.whl (26 kB)\n",
            "Downloading rpds_py-0.24.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (389 kB)\n",
            "Downloading scs-3.2.7.post2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m132.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
            "Downloading soupsieve-2.6-py3-none-any.whl (36 kB)\n",
            "Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
            "Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m150.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading traitlets-5.14.3-py3-none-any.whl (85 kB)\n",
            "Downloading typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
            "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Downloading decorator-5.2.1-py3-none-any.whl (9.2 kB)\n",
            "Downloading ipython_pygments_lexers-1.1.1-py3-none-any.whl (8.1 kB)\n",
            "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Downloading matplotlib_inline-0.1.7-py3-none-any.whl (9.9 kB)\n",
            "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Downloading stack_data-0.6.3-py3-none-any.whl (24 kB)\n",
            "Downloading wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n",
            "Downloading asttokens-3.0.0-py3-none-any.whl (26 kB)\n",
            "Downloading executing-2.2.0-py2.py3-none-any.whl (26 kB)\n",
            "Downloading google_auth-2.38.0-py2.py3-none-any.whl (210 kB)\n",
            "Downloading googleapis_common_protos-1.69.2-py3-none-any.whl (293 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading parso-0.8.4-py2.py3-none-any.whl (103 kB)\n",
            "Downloading proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
            "Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
            "Downloading pure_eval-0.2.3-py3-none-any.whl (11 kB)\n",
            "Downloading wcwidth-0.2.13-py2.py3-none-any.whl (34 kB)\n",
            "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
            "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
            "Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
            "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
            "Building wheels for collected packages: finrl, msgpack, elegantrl, peewee, thriftpy2\n",
            "  Building wheel for finrl (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for finrl: filename=finrl-0.3.8-py3-none-any.whl size=4702655 sha256=29575c4030eb7037667ac4d976ce285a35c463e68b3d0652ebe868f63d965dd8\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-xjitfxb5/wheels/22/04/d2/8ee1f0ed6a91622a6548d244772ae124a9b3795372817286a0\n",
            "  Building wheel for msgpack (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for msgpack: filename=msgpack-1.0.3-cp311-cp311-linux_x86_64.whl size=15688 sha256=7c82906145c9b341d5f73d0ae735c60838644ece9d7ead40039f20cbde875e2f\n",
            "  Stored in directory: /root/.cache/pip/wheels/f6/35/da/ed9b26b510235e00e3a3c3bab7bad97b59214729662255ab3d\n",
            "  Building wheel for elegantrl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for elegantrl: filename=ElegantRL-0.3.10-py3-none-any.whl size=272004 sha256=934e8bdae8a1865b768b40f8761465717e139246b8c3517e51c5095324a93ac9\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-xjitfxb5/wheels/9a/77/4d/6284111037b2dd64af9ef18d4d600d9c185cc2f6f09704e896\n",
            "  Building wheel for peewee (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for peewee: filename=peewee-3.17.3-cp311-cp311-linux_x86_64.whl size=274419 sha256=9f5b56aa86db57e13f3242f15c6368297f513b3d4e8ce80c873c068713b1c588\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/3d/30/a54ad8c2307aa653f234a6f651ab12fbc5cfbb3f383145ab6a\n",
            "  Building wheel for thriftpy2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for thriftpy2: filename=thriftpy2-0.5.2-cp311-cp311-linux_x86_64.whl size=841210 sha256=d77e2bb8588fbe8bd0cbc9cb14fe30c86a4b6a02d15cad526dbb2d13914b6f29\n",
            "  Stored in directory: /root/.cache/pip/wheels/17/32/fa/51ae0364792430fb80858f4705c9e0cba3d6900f591f0c4495\n",
            "Successfully built finrl msgpack elegantrl peewee thriftpy2\n",
            "Installing collected packages: wcwidth, triton, sseclient-py, sortedcontainers, pytz, py-spy, pure-eval, ptyprocess, ply, peewee, opencensus-context, nvidia-cusparselt-cu12, multitasking, msgpack, mpmath, farama-notifications, distlib, colorful, wrapt, websockets, websocket-client, urllib3, tzdata, typing_extensions, traitlets, threadpoolctl, tensorboard-data-server, tenacity, sympy, soupsieve, sniffio, six, rpds-py, PyYAML, python-dotenv, pyparsing, pymysql, pygments, pygame, pyasn1, pyarrow, psycopg2-binary, psutil, protobuf, propcache, prompt_toolkit, prometheus_client, pillow, pexpect, parso, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, niltype, networkx, multidict, mdurl, MarkupSafe, markdown, kiwisolver, joblib, h11, grpcio, greenlet, fsspec, frozenlist, fonttools, filelock, executing, deprecation, decorator, Cython, cycler, cloudpickle, click, cachetools, attrs, asttokens, annotated-types, aiohappyeyeballs, absl-py, yarl, wsproto, werkzeug, virtualenv, typing-inspection, thriftpy2, th, tensorboardX, stack_data, SQLAlchemy, smart_open, scipy, rsa, referencing, python-dateutil, pydantic-core, pycares, pyasn1-modules, proto-plus, plotly, outcome, opencv-python, nvidia-cusparse-cu12, nvidia-cudnn-cu12, matplotlib-inline, markdown-it-py, jinja2, jedi, ipython-pygments-lexers, gymnasium, googleapis-common-protos, cryptography, contourpy, bottleneck, beautifulsoup4, ale-py, aiosignal, webdriver-manager, trio, tensorboard, scs, scikit-learn, rich, pydantic, pandas, osqp, nvidia-cusolver-cu12, matplotlib, jsonschema-specifications, ipython, google-auth, ecos, clarabel, aiohttp, aiodns, yfinance, wrds, trio-websocket, torch, stockstats, seaborn, jsonschema, jqdatasdk, google-api-core, empyrical-reloaded, elegantrl, cvxpy, ccxt, alpaca-trade-api, alpaca-py, aiohttp_cors, stable-baselines3, selenium, ray, pyportfolioopt, pyfolio-reloaded, opencensus, finrl\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.3.0\n",
            "    Uninstalling urllib3-2.3.0:\n",
            "      Successfully uninstalled urllib3-2.3.0\n",
            "Successfully installed Cython-3.0.12 MarkupSafe-3.0.2 PyYAML-6.0.1 SQLAlchemy-2.0.40 absl-py-2.2.2 aiodns-3.2.0 aiohappyeyeballs-2.6.1 aiohttp-3.11.16 aiohttp_cors-0.8.1 aiosignal-1.3.2 ale-py-0.10.2 alpaca-py-0.37.0 alpaca-trade-api-3.2.0 annotated-types-0.7.0 asttokens-3.0.0 attrs-25.3.0 beautifulsoup4-4.13.3 bottleneck-1.4.2 cachetools-5.5.2 ccxt-3.1.60 clarabel-0.10.0 click-8.1.8 cloudpickle-3.1.1 colorful-0.5.6 contourpy-1.3.1 cryptography-44.0.2 cvxpy-1.6.4 cycler-0.12.1 decorator-5.2.1 deprecation-2.1.0 distlib-0.3.9 ecos-2.0.14 elegantrl-0.3.10 empyrical-reloaded-0.5.11 executing-2.2.0 farama-notifications-0.0.4 filelock-3.18.0 finrl-0.3.8 fonttools-4.57.0 frozenlist-1.5.0 fsspec-2025.3.2 google-api-core-2.24.2 google-auth-2.38.0 googleapis-common-protos-1.69.2 greenlet-3.1.1 grpcio-1.71.0 gymnasium-1.1.1 h11-0.14.0 ipython-9.1.0 ipython-pygments-lexers-1.1.1 jedi-0.19.2 jinja2-3.1.6 joblib-1.4.2 jqdatasdk-1.9.7 jsonschema-4.23.0 jsonschema-specifications-2024.10.1 kiwisolver-1.4.8 markdown-3.8 markdown-it-py-3.0.0 matplotlib-3.10.1 matplotlib-inline-0.1.7 mdurl-0.1.2 mpmath-1.3.0 msgpack-1.0.3 multidict-6.4.3 multitasking-0.0.11 networkx-3.4.2 niltype-1.0.2 numpy-2.2.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 opencensus-0.11.4 opencensus-context-0.1.3 opencv-python-4.11.0.86 osqp-1.0.3 outcome-1.3.0.post0 pandas-2.2.3 parso-0.8.4 peewee-3.17.3 pexpect-4.9.0 pillow-11.2.1 plotly-5.24.1 ply-3.11 prometheus_client-0.21.1 prompt_toolkit-3.0.50 propcache-0.3.1 proto-plus-1.26.1 protobuf-6.30.2 psutil-7.0.0 psycopg2-binary-2.9.10 ptyprocess-0.7.0 pure-eval-0.2.3 py-spy-0.4.0 pyarrow-19.0.1 pyasn1-0.6.1 pyasn1-modules-0.4.2 pycares-4.6.0 pydantic-2.11.3 pydantic-core-2.33.1 pyfolio-reloaded-0.9.8 pygame-2.6.1 pygments-2.19.1 pymysql-1.1.1 pyparsing-3.2.3 pyportfolioopt-1.5.6 python-dateutil-2.9.0.post0 python-dotenv-1.1.0 pytz-2025.2 ray-2.44.1 referencing-0.36.2 rich-14.0.0 rpds-py-0.24.0 rsa-4.9 scikit-learn-1.6.1 scipy-1.15.2 scs-3.2.7.post2 seaborn-0.13.2 selenium-4.31.0 six-1.17.0 smart_open-7.1.0 sniffio-1.3.1 sortedcontainers-2.4.0 soupsieve-2.6 sseclient-py-1.8.0 stable-baselines3-2.6.0 stack_data-0.6.3 stockstats-0.5.4 sympy-1.13.1 tenacity-9.1.2 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorboardX-2.6.2.2 th-0.4.1 threadpoolctl-3.6.0 thriftpy2-0.5.2 torch-2.6.0 traitlets-5.14.3 trio-0.29.0 trio-websocket-0.12.2 triton-3.2.0 typing-inspection-0.4.0 typing_extensions-4.13.2 tzdata-2025.2 urllib3-1.26.20 virtualenv-20.30.0 wcwidth-0.2.13 webdriver-manager-4.0.2 websocket-client-1.8.0 websockets-10.4 werkzeug-3.1.3 wrapt-1.17.2 wrds-3.3.0 wsproto-1.2.0 yarl-1.19.0 yfinance-0.2.55\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cycler",
                  "google",
                  "kiwisolver",
                  "matplotlib_inline",
                  "pexpect",
                  "prompt_toolkit",
                  "six",
                  "wcwidth"
                ]
              },
              "id": "4451512197ee46d7ab7c79b77457e2dd"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ## install finrl library\n",
        "!pip install wrds\n",
        "!pip install swig\n",
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()\n",
        "!apt-get update -y -qq && apt-get install -y -qq cmake libopenmpi-dev python3-dev zlib1g-dev libgl1-mesa-glx swig\n",
        "!pip install git+https://github.com/AI4Finance-Foundation/FinRL.git\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osBHhVysOEzi"
      },
      "source": [
        "\n",
        "<a id='1.2'></a>\n",
        "## 2.2. Check if the additional packages needed are present, if not install them.\n",
        "* Yahoo Finance API\n",
        "* pandas\n",
        "* numpy\n",
        "* matplotlib\n",
        "* stockstats\n",
        "* OpenAI gym\n",
        "* stable-baselines\n",
        "* tensorflow\n",
        "* pyfolio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGv01K8Sh1hn"
      },
      "source": [
        "<a id='1.3'></a>\n",
        "## 2.3. Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "EeMK7Uentj1V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "049fd7d2-72ef-4e72-a365-30e91135ab0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pandas_market_calendars\n",
            "  Downloading pandas_market_calendars-5.0.0-py3-none-any.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: pandas>=1.1 in /usr/local/lib/python3.11/site-packages (from pandas_market_calendars) (2.2.3)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.11/site-packages (from pandas_market_calendars) (2025.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/site-packages (from pandas_market_calendars) (2.9.0.post0)\n",
            "Collecting exchange-calendars>=3.3 (from pandas_market_calendars)\n",
            "  Downloading exchange_calendars-4.10-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/site-packages (from exchange-calendars>=3.3->pandas_market_calendars) (2.2.4)\n",
            "Collecting pyluach (from exchange-calendars>=3.3->pandas_market_calendars)\n",
            "  Downloading pyluach-2.2.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting toolz (from exchange-calendars>=3.3->pandas_market_calendars)\n",
            "  Downloading toolz-1.0.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting korean_lunar_calendar (from exchange-calendars>=3.3->pandas_market_calendars)\n",
            "  Downloading korean_lunar_calendar-0.3.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/site-packages (from pandas>=1.1->pandas_market_calendars) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/site-packages (from python-dateutil->pandas_market_calendars) (1.17.0)\n",
            "Downloading pandas_market_calendars-5.0.0-py3-none-any.whl (122 kB)\n",
            "Downloading exchange_calendars-4.10-py3-none-any.whl (198 kB)\n",
            "Downloading korean_lunar_calendar-0.3.1-py3-none-any.whl (9.0 kB)\n",
            "Downloading pyluach-2.2.0-py3-none-any.whl (25 kB)\n",
            "Downloading toolz-1.0.0-py3-none-any.whl (56 kB)\n",
            "Installing collected packages: korean_lunar_calendar, toolz, pyluach, exchange-calendars, pandas_market_calendars\n",
            "Successfully installed exchange-calendars-4.10 korean_lunar_calendar-0.3.1 pandas_market_calendars-5.0.0 pyluach-2.2.0 toolz-1.0.0\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "!pip install pandas_market_calendars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lPqeTTwoh1hn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "# matplotlib.use('Agg')\n",
        "import datetime\n",
        "\n",
        "%matplotlib inline\n",
        "from finrl.config_tickers import DOW_30_TICKER\n",
        "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
        "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
        "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
        "from finrl.agents.stablebaselines3.models import DRLAgent,DRLEnsembleAgent\n",
        "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
        "\n",
        "from pprint import pprint\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"../FinRL-Library\")\n",
        "\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2owTj985RW4"
      },
      "source": [
        "<a id='1.4'></a>\n",
        "## 2.4. Create Folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "w9A8CN5R5PuZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from finrl.main import check_and_make_directories\n",
        "from finrl.config import (\n",
        "    DATA_SAVE_DIR,\n",
        "    TRAINED_MODEL_DIR,\n",
        "    TENSORBOARD_LOG_DIR,\n",
        "    RESULTS_DIR,\n",
        "    INDICATORS,\n",
        "    TRAIN_START_DATE,\n",
        "    TRAIN_END_DATE,\n",
        "    TEST_START_DATE,\n",
        "    TEST_END_DATE,\n",
        "    TRADE_START_DATE,\n",
        "    TRADE_END_DATE,\n",
        ")\n",
        "\n",
        "check_and_make_directories([DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A289rQWMh1hq"
      },
      "source": [
        "<a id='2'></a>\n",
        "# Part 3. Download Data\n",
        "Yahoo Finance is a website that provides stock data, financial news, financial reports, etc. All the data provided by Yahoo Finance is free.\n",
        "* FinRL uses a class **YahooDownloader** to fetch data from Yahoo Finance API\n",
        "* Call Limit: Using the Public API (without authentication), you are limited to 2,000 requests per hour per IP (or up to a total of 48,000 requests a day).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPeQ7iS-LoMm"
      },
      "source": [
        "\n",
        "\n",
        "-----\n",
        "class YahooDownloader:\n",
        "    Provides methods for retrieving daily stock data from\n",
        "    Yahoo Finance API\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "        start_date : str\n",
        "            start date of the data (modified from config.py)\n",
        "        end_date : str\n",
        "            end date of the data (modified from config.py)\n",
        "        ticker_list : list\n",
        "            a list of stock tickers (modified from config.py)\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    fetch_data()\n",
        "        Fetches data from yahoo API\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzqRRTOX6aFu"
      },
      "outputs": [],
      "source": [
        "print(DOW_30_TICKER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCKm4om-s9kE",
        "outputId": "52164ded-8567-4cf6-db04-a8b5bf5b13b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of DataFrame:  (112703, 8)\n"
          ]
        }
      ],
      "source": [
        "# TRAIN_START_DATE = '2009-04-01'\n",
        "# TRAIN_END_DATE = '2021-01-01'\n",
        "# TEST_START_DATE = '2021-01-01'\n",
        "# TEST_END_DATE = '2022-06-01'\n",
        "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
        "from finrl.config_tickers import DOW_30_TICKER\n",
        "\n",
        "TRAIN_START_DATE = '2010-01-01'\n",
        "TRAIN_END_DATE = '2021-10-01'\n",
        "TEST_START_DATE = '2021-10-01'\n",
        "TEST_END_DATE = '2025-04-01'\n",
        "\n",
        "df = YahooDownloader(start_date = TRAIN_START_DATE,\n",
        "                     end_date = TEST_END_DATE,\n",
        "                     ticker_list = DOW_30_TICKER).fetch_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqC6c40Zh1iH"
      },
      "source": [
        "# Part 4: Preprocess Data\n",
        "Data preprocessing is a crucial step for training a high quality machine learning model. We need to check for missing data and do feature engineering in order to convert the data into a model-ready state.\n",
        "* Add technical indicators. In practical trading, various information needs to be taken into account, for example the historical stock prices, current holding shares, technical indicators, etc. In this article, we demonstrate two trend-following technical indicators: MACD and RSI.\n",
        "* Add turbulence index. Risk-aversion reflects whether an investor will choose to preserve the capital. It also influences one's trading strategy when facing different market volatility level. To control the risk in a worst-case scenario, such as financial crisis of 2007–2008, FinRL employs the financial turbulence index that measures extreme asset price fluctuation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "kM5bH9uroCeg"
      },
      "outputs": [],
      "source": [
        " INDICATORS = ['macd',\n",
        "               'rsi_30',\n",
        "               'cci_30',\n",
        "               'dx_30']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgXfBcjxtj1a",
        "outputId": "3c80b59e-31a6-47ec-c0b7-63903abba0c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully added technical indicators\n",
            "Successfully added turbulence index\n"
          ]
        }
      ],
      "source": [
        "from finrl.meta.preprocessor.preprocessors import FeatureEngineer\n",
        "fe = FeatureEngineer(use_technical_indicator=True,\n",
        "                     tech_indicator_list = INDICATORS,\n",
        "                     use_turbulence=True,\n",
        "                     user_defined_feature = False)\n",
        "\n",
        "processed = fe.preprocess_data(df)\n",
        "processed = processed.copy()\n",
        "processed = processed.fillna(0)\n",
        "processed = processed.replace(np.inf,0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#len(state), len(data)"
      ],
      "metadata": {
        "id": "tiFA3pRWPQMO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "99cc7b4a-c044-4c88-9c39-fcbb4b744f54"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'state' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-2ee8879d87db>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'state' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QsYaY0Dh1iw"
      },
      "source": [
        "<a id='4'></a>\n",
        "# Part 5. Design Environment\n",
        "Considering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\n",
        "\n",
        "Our trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\n",
        "\n",
        "The action space describes the allowed actions that the agent interacts with the environment. Normally, action a includes three actions: {-1, 0, 1}, where -1, 0, 1 represent selling, holding, and buying one share. Also, an action can be carried upon multiple shares. We use an action space {-k,…,-1, 0, 1, …, k}, where k denotes the number of shares to buy and -k denotes the number of shares to sell. For example, \"Buy 10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or -10, respectively. The continuous action space needs to be normalized to [-1, 1], since the policy is defined on a Gaussian distribution, which needs to be normalized and symmetric."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2zqII8rMIqn",
        "outputId": "295f33e3-015a-45b0-dd59-329b1dfe8c50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stock Dimension: 29, State Space: 175\n"
          ]
        }
      ],
      "source": [
        "stock_dimension = len(processed.tic.unique())\n",
        "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\n",
        "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "AWyp84Ltto19"
      },
      "outputs": [],
      "source": [
        "env_kwargs = {\n",
        "    \"hmax\": 100,\n",
        "    \"initial_amount\": 1000000,\n",
        "    \"buy_cost_pct\": 0.001,\n",
        "    \"sell_cost_pct\": 0.001,\n",
        "    \"state_space\": state_space,\n",
        "    \"stock_dim\": stock_dimension,\n",
        "    \"tech_indicator_list\": INDICATORS,\n",
        "    \"action_space\": stock_dimension,\n",
        "    \"reward_scaling\": 1e-4,\n",
        "    \"print_verbosity\":5\n",
        "\n",
        "}\n",
        "\n",
        "# buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
        "# num_stock_shares = [0] * stock_dimension\n",
        "# env_kwargs = {\n",
        "#     \"hmax\": 100,\n",
        "#     \"initial_amount\": 1000000,\n",
        "#     \"num_stock_shares\": num_stock_shares,\n",
        "#     \"buy_cost_pct\": buy_cost_list,\n",
        "#     \"sell_cost_pct\": sell_cost_list,\n",
        "#     \"state_space\": state_space,\n",
        "#     \"stock_dim\": stock_dimension,\n",
        "#     \"tech_indicator_list\": INDICATORS,\n",
        "#     \"action_space\": stock_dimension,\n",
        "#     \"reward_scaling\": 1e-4\n",
        "# }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMNR5nHjh1iz"
      },
      "source": [
        "<a id='5'></a>\n",
        "# Part 6: Implement DRL Algorithms\n",
        "* The implementation of the DRL algorithms are based on **OpenAI Baselines** and **Stable Baselines**. Stable Baselines is a fork of OpenAI Baselines, with a major structural refactoring, and code cleanups.\n",
        "* FinRL library includes fine-tuned standard DRL algorithms, such as DQN, DDPG,\n",
        "Multi-Agent DDPG, PPO, SAC, A2C and TD3. We also allow users to\n",
        "design their own DRL algorithms by adapting these DRL algorithms.\n",
        "\n",
        "* In this notebook, we are training and validating 3 agents (A2C, PPO, DDPG) using Rolling-window Ensemble Method ([reference code](https://github.com/AI4Finance-LLC/Deep-Reinforcement-Learning-for-Automated-Stock-Trading-Ensemble-Strategy-ICAIF-2020/blob/80415db8fa7b2179df6bd7e81ce4fe8dbf913806/model/models.py#L92))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "v-gthCxMtj1d"
      },
      "outputs": [],
      "source": [
        "rebalance_window = 63 # rebalance_window is the number of days to retrain the model\n",
        "validation_window = 63 # validation_window is the number of days to do validation and trading (e.g. if validation_window=63, then both validation and trading period will be 63 days)\n",
        "\n",
        "ensemble_agent = DRLEnsembleAgent(df=processed,\n",
        "                 train_period=(TRAIN_START_DATE,TRAIN_END_DATE),\n",
        "                 val_test_period=(TEST_START_DATE,TEST_END_DATE),\n",
        "                 rebalance_window=rebalance_window,\n",
        "                 validation_window=validation_window,\n",
        "                 **env_kwargs)\n",
        "# e_train_gym = StockTradingEnv(df = processed, **env_kwargs)\n",
        "# agent = DRLAgent(e_train_gym)\n",
        "# if_using_a2c = True\n",
        "# model_a2c = agent.get_model(\"a2c\")\n",
        "# # if if_using_a2c:\n",
        "# #   tmp_path = RESULTS_DIR + '/a2c'\n",
        "# #   new_logger_a2c = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
        "# #   model_a2c.set_logger(new_logger_a2c)\n",
        "# trained_a2c = agent.train_model(model=model_a2c,\n",
        "#                              tb_log_name='a2c',\n",
        "#                              total_timesteps=50000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "KsfEHa_Etj1d",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "A2C_model_kwargs = {\n",
        "                    'n_steps': 5,\n",
        "                    'ent_coef': 0.005,\n",
        "                    'learning_rate': 0.0007\n",
        "                    }\n",
        "\n",
        "PPO_model_kwargs = {\n",
        "                    \"ent_coef\":0.01,\n",
        "                    \"n_steps\": 2048,\n",
        "                    \"learning_rate\": 0.00025,\n",
        "                    \"batch_size\": 128\n",
        "                    }\n",
        "\n",
        "DDPG_model_kwargs = {\n",
        "                      #\"action_noise\":\"ornstein_uhlenbeck\",\n",
        "                      \"buffer_size\": 10_000,\n",
        "                      \"learning_rate\": 0.0005,\n",
        "                      \"batch_size\": 64\n",
        "                    }\n",
        "\n",
        "SAC_model_kwargs = {\n",
        "    \"batch_size\": 64,\n",
        "    \"buffer_size\": 100000,\n",
        "    \"learning_rate\": 0.0001,\n",
        "    \"learning_starts\": 100,\n",
        "    \"ent_coef\": \"auto_0.1\",\n",
        "}\n",
        "\n",
        "TD3_model_kwargs = {\"batch_size\": 100, \"buffer_size\": 1000000, \"learning_rate\": 0.0001}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "timesteps_dict = {'a2c' : 10_000,\n",
        "                 'ppo' : 10_000,\n",
        "                 'ddpg' : 10_000,\n",
        "                 'sac' : 10_000,\n",
        "                 'td3' : 10_000\n",
        "                 }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1lyCECstj1e",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c55e81b7-75e9-4afc-f602-21d341491a8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============Start Ensemble Strategy============\n",
            "============================================\n",
            "turbulence_threshold:  201.71766389369628\n",
            "======Model training from:  2010-01-01 to  2021-10-04\n",
            "======a2c Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/a2c/a2c_126_1\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 92         |\n",
            "|    iterations         | 100        |\n",
            "|    time_elapsed       | 5          |\n",
            "|    total_timesteps    | 500        |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41        |\n",
            "|    explained_variance | -0.139     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 99         |\n",
            "|    policy_loss        | -49.9      |\n",
            "|    reward             | 0.24180529 |\n",
            "|    std                | 0.996      |\n",
            "|    value_loss         | 2.02       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 90         |\n",
            "|    iterations         | 200        |\n",
            "|    time_elapsed       | 11         |\n",
            "|    total_timesteps    | 1000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41        |\n",
            "|    explained_variance | 0.0133     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 199        |\n",
            "|    policy_loss        | -27.4      |\n",
            "|    reward             | 0.35951546 |\n",
            "|    std                | 0.996      |\n",
            "|    value_loss         | 2.67       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 92         |\n",
            "|    iterations         | 300        |\n",
            "|    time_elapsed       | 16         |\n",
            "|    total_timesteps    | 1500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.1      |\n",
            "|    explained_variance | 0.0163     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 299        |\n",
            "|    policy_loss        | -29        |\n",
            "|    reward             | -3.7623115 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 3.28       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 94         |\n",
            "|    iterations         | 400        |\n",
            "|    time_elapsed       | 21         |\n",
            "|    total_timesteps    | 2000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | -0.0276    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 399        |\n",
            "|    policy_loss        | -58.2      |\n",
            "|    reward             | 0.34011766 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 9.06       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 92         |\n",
            "|    iterations         | 500        |\n",
            "|    time_elapsed       | 27         |\n",
            "|    total_timesteps    | 2500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | 0.0179     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 499        |\n",
            "|    policy_loss        | -215       |\n",
            "|    reward             | -2.5692725 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 28         |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 93       |\n",
            "|    iterations         | 600      |\n",
            "|    time_elapsed       | 31       |\n",
            "|    total_timesteps    | 3000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.1    |\n",
            "|    explained_variance | -19.5    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 599      |\n",
            "|    policy_loss        | 70.5     |\n",
            "|    reward             | 1.237817 |\n",
            "|    std                | 0.998    |\n",
            "|    value_loss         | 7.66     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 92         |\n",
            "|    iterations         | 700        |\n",
            "|    time_elapsed       | 37         |\n",
            "|    total_timesteps    | 3500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41        |\n",
            "|    explained_variance | -0.455     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 699        |\n",
            "|    policy_loss        | 19.4       |\n",
            "|    reward             | 0.78271276 |\n",
            "|    std                | 0.996      |\n",
            "|    value_loss         | 0.566      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 93          |\n",
            "|    iterations         | 800         |\n",
            "|    time_elapsed       | 42          |\n",
            "|    total_timesteps    | 4000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41         |\n",
            "|    explained_variance | -0.102      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 799         |\n",
            "|    policy_loss        | 83.1        |\n",
            "|    reward             | -0.68068784 |\n",
            "|    std                | 0.996       |\n",
            "|    value_loss         | 8.01        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 92         |\n",
            "|    iterations         | 900        |\n",
            "|    time_elapsed       | 48         |\n",
            "|    total_timesteps    | 4500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 899        |\n",
            "|    policy_loss        | -229       |\n",
            "|    reward             | 0.18648413 |\n",
            "|    std                | 0.996      |\n",
            "|    value_loss         | 53.2       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 93        |\n",
            "|    iterations         | 1000      |\n",
            "|    time_elapsed       | 53        |\n",
            "|    total_timesteps    | 5000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41       |\n",
            "|    explained_variance | -0.00592  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 999       |\n",
            "|    policy_loss        | -471      |\n",
            "|    reward             | 0.9394727 |\n",
            "|    std                | 0.996     |\n",
            "|    value_loss         | 258       |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 93        |\n",
            "|    iterations         | 1100      |\n",
            "|    time_elapsed       | 58        |\n",
            "|    total_timesteps    | 5500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41       |\n",
            "|    explained_variance | 0.0157    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1099      |\n",
            "|    policy_loss        | -198      |\n",
            "|    reward             | 5.3664556 |\n",
            "|    std                | 0.996     |\n",
            "|    value_loss         | 55.3      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 93        |\n",
            "|    iterations         | 1200      |\n",
            "|    time_elapsed       | 64        |\n",
            "|    total_timesteps    | 6000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41       |\n",
            "|    explained_variance | -0.0803   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1199      |\n",
            "|    policy_loss        | -13.1     |\n",
            "|    reward             | -0.811825 |\n",
            "|    std                | 0.996     |\n",
            "|    value_loss         | 0.673     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 93        |\n",
            "|    iterations         | 1300      |\n",
            "|    time_elapsed       | 69        |\n",
            "|    total_timesteps    | 6500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41       |\n",
            "|    explained_variance | 0.113     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1299      |\n",
            "|    policy_loss        | -61.9     |\n",
            "|    reward             | 0.5630602 |\n",
            "|    std                | 0.995     |\n",
            "|    value_loss         | 5.05      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 93       |\n",
            "|    iterations         | 1400     |\n",
            "|    time_elapsed       | 75       |\n",
            "|    total_timesteps    | 7000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41      |\n",
            "|    explained_variance | -0.00406 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1399     |\n",
            "|    policy_loss        | -19.1    |\n",
            "|    reward             | -1.52834 |\n",
            "|    std                | 0.996    |\n",
            "|    value_loss         | 1.43     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 93         |\n",
            "|    iterations         | 1500       |\n",
            "|    time_elapsed       | 80         |\n",
            "|    total_timesteps    | 7500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41        |\n",
            "|    explained_variance | -0.771     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1499       |\n",
            "|    policy_loss        | 46.3       |\n",
            "|    reward             | -1.5187869 |\n",
            "|    std                | 0.996      |\n",
            "|    value_loss         | 2.14       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 93        |\n",
            "|    iterations         | 1600      |\n",
            "|    time_elapsed       | 85        |\n",
            "|    total_timesteps    | 8000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41       |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1599      |\n",
            "|    policy_loss        | 7.97      |\n",
            "|    reward             | 2.0313323 |\n",
            "|    std                | 0.996     |\n",
            "|    value_loss         | 3.21      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 93        |\n",
            "|    iterations         | 1700      |\n",
            "|    time_elapsed       | 90        |\n",
            "|    total_timesteps    | 8500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1699      |\n",
            "|    policy_loss        | -43.4     |\n",
            "|    reward             | 1.4067931 |\n",
            "|    std                | 0.995     |\n",
            "|    value_loss         | 24.6      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 93        |\n",
            "|    iterations         | 1800      |\n",
            "|    time_elapsed       | 96        |\n",
            "|    total_timesteps    | 9000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.1     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1799      |\n",
            "|    policy_loss        | -41.2     |\n",
            "|    reward             | 0.6260048 |\n",
            "|    std                | 0.998     |\n",
            "|    value_loss         | 1.86      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 93       |\n",
            "|    iterations         | 1900     |\n",
            "|    time_elapsed       | 101      |\n",
            "|    total_timesteps    | 9500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.1    |\n",
            "|    explained_variance | 0.0956   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1899     |\n",
            "|    policy_loss        | 55.9     |\n",
            "|    reward             | 1.230997 |\n",
            "|    std                | 0.997    |\n",
            "|    value_loss         | 3.94     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 93        |\n",
            "|    iterations         | 2000      |\n",
            "|    time_elapsed       | 106       |\n",
            "|    total_timesteps    | 10000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.1     |\n",
            "|    explained_variance | 0.262     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1999      |\n",
            "|    policy_loss        | 54.4      |\n",
            "|    reward             | 1.9357569 |\n",
            "|    std                | 0.998     |\n",
            "|    value_loss         | 2.17      |\n",
            "-------------------------------------\n",
            "======a2c Validation from:  2021-10-04 to  2022-01-03\n",
            "a2c Sharpe Ratio:  0.20943071631830354\n",
            "======ddpg Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ddpg/ddpg_126_1\n",
            "day: 2957, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 4004115.13\n",
            "total_reward: 3004115.13\n",
            "total_cost: 5962.31\n",
            "total_trades: 42915\n",
            "Sharpe: 0.736\n",
            "=================================\n",
            "======ddpg Validation from:  2021-10-04 to  2022-01-03\n",
            "ddpg Sharpe Ratio:  0.15283239563815598\n",
            "======td3 Training========\n",
            "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.0001}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/td3/td3_126_1\n",
            "day: 2957, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 7080693.39\n",
            "total_reward: 6080693.39\n",
            "total_cost: 1426.94\n",
            "total_trades: 35331\n",
            "Sharpe: 1.081\n",
            "=================================\n",
            "======td3 Validation from:  2021-10-04 to  2022-01-03\n",
            "td3 Sharpe Ratio:  0.23389288025335583\n",
            "======sac Training========\n",
            "{'batch_size': 64, 'buffer_size': 100000, 'learning_rate': 0.0001, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/sac/sac_126_1\n",
            "day: 2957, episode: 15\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 3779518.52\n",
            "total_reward: 2779518.52\n",
            "total_cost: 233670.20\n",
            "total_trades: 68290\n",
            "Sharpe: 0.736\n",
            "=================================\n",
            "======sac Validation from:  2021-10-04 to  2022-01-03\n",
            "sac Sharpe Ratio:  0.09395396289712886\n",
            "======ppo Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ppo/ppo_126_1\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    fps             | 99        |\n",
            "|    iterations      | 1         |\n",
            "|    time_elapsed    | 20        |\n",
            "|    total_timesteps | 2048      |\n",
            "| train/             |           |\n",
            "|    reward          | 1.1842471 |\n",
            "----------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 99          |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 41          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016268235 |\n",
            "|    clip_fraction        | 0.191       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | -0.0436     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 4.99        |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0288     |\n",
            "|    reward               | 1.3119783   |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 12.9        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 97          |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 63          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.02896595  |\n",
            "|    clip_fraction        | 0.287       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | -0.00934    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 22.9        |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0193     |\n",
            "|    reward               | -0.20365398 |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 38.2        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 96          |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 84          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014725586 |\n",
            "|    clip_fraction        | 0.143       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.3       |\n",
            "|    explained_variance   | -0.000778   |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 53.9        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0156     |\n",
            "|    reward               | 3.7431567   |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 106         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 96          |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 105         |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018677775 |\n",
            "|    clip_fraction        | 0.227       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.3       |\n",
            "|    explained_variance   | -0.0113     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 7.84        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0165     |\n",
            "|    reward               | 0.06737236  |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 15.3        |\n",
            "-----------------------------------------\n",
            "======ppo Validation from:  2021-10-04 to  2022-01-03\n",
            "ppo Sharpe Ratio:  0.14227544922999535\n",
            "======Best Model Retraining from:  2010-01-01 to  2022-01-03\n",
            "======Trading from:  2022-01-03 to  2022-04-04\n",
            "============================================\n",
            "turbulence_threshold:  201.71766389369628\n",
            "======Model training from:  2010-01-01 to  2022-01-03\n",
            "======a2c Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/a2c/a2c_189_1\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 96         |\n",
            "|    iterations         | 100        |\n",
            "|    time_elapsed       | 5          |\n",
            "|    total_timesteps    | 500        |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 99         |\n",
            "|    policy_loss        | -21.8      |\n",
            "|    reward             | 0.17086078 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 0.611      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 89         |\n",
            "|    iterations         | 200        |\n",
            "|    time_elapsed       | 11         |\n",
            "|    total_timesteps    | 1000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 199        |\n",
            "|    policy_loss        | -22.2      |\n",
            "|    reward             | 0.27985525 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 2.92       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 92         |\n",
            "|    iterations         | 300        |\n",
            "|    time_elapsed       | 16         |\n",
            "|    total_timesteps    | 1500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 299        |\n",
            "|    policy_loss        | -17.3      |\n",
            "|    reward             | -2.2901435 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 3.96       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 91        |\n",
            "|    iterations         | 400       |\n",
            "|    time_elapsed       | 21        |\n",
            "|    total_timesteps    | 2000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.3     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 399       |\n",
            "|    policy_loss        | 71.8      |\n",
            "|    reward             | 5.7310805 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 24.7      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 90         |\n",
            "|    iterations         | 500        |\n",
            "|    time_elapsed       | 27         |\n",
            "|    total_timesteps    | 2500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 499        |\n",
            "|    policy_loss        | -191       |\n",
            "|    reward             | -1.7282736 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 19.3       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 91       |\n",
            "|    iterations         | 600      |\n",
            "|    time_elapsed       | 32       |\n",
            "|    total_timesteps    | 3000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.2    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 599      |\n",
            "|    policy_loss        | -14      |\n",
            "|    reward             | 8.253177 |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 7.42     |\n",
            "------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 90          |\n",
            "|    iterations         | 700         |\n",
            "|    time_elapsed       | 38          |\n",
            "|    total_timesteps    | 3500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.2       |\n",
            "|    explained_variance | 0.0103      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 699         |\n",
            "|    policy_loss        | -121        |\n",
            "|    reward             | -0.40951586 |\n",
            "|    std                | 1           |\n",
            "|    value_loss         | 9.67        |\n",
            "---------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 91       |\n",
            "|    iterations         | 800      |\n",
            "|    time_elapsed       | 43       |\n",
            "|    total_timesteps    | 4000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.1    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 799      |\n",
            "|    policy_loss        | 115      |\n",
            "|    reward             | 1.023042 |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 8.67     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 90        |\n",
            "|    iterations         | 900       |\n",
            "|    time_elapsed       | 49        |\n",
            "|    total_timesteps    | 4500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.1     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 899       |\n",
            "|    policy_loss        | -82.4     |\n",
            "|    reward             | 0.4672636 |\n",
            "|    std                | 0.999     |\n",
            "|    value_loss         | 6.93      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 90        |\n",
            "|    iterations         | 1000      |\n",
            "|    time_elapsed       | 55        |\n",
            "|    total_timesteps    | 5000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 999       |\n",
            "|    policy_loss        | 164       |\n",
            "|    reward             | -0.592448 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 23.3      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 89        |\n",
            "|    iterations         | 1100      |\n",
            "|    time_elapsed       | 61        |\n",
            "|    total_timesteps    | 5500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1099      |\n",
            "|    policy_loss        | 198       |\n",
            "|    reward             | 10.995463 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 65.1      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 90         |\n",
            "|    iterations         | 1200       |\n",
            "|    time_elapsed       | 66         |\n",
            "|    total_timesteps    | 6000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | -3.19e-05  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1199       |\n",
            "|    policy_loss        | 1.05e+03   |\n",
            "|    reward             | -2.9664476 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 1.1e+03    |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 89        |\n",
            "|    iterations         | 1300      |\n",
            "|    time_elapsed       | 72        |\n",
            "|    total_timesteps    | 6500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1299      |\n",
            "|    policy_loss        | -5.67     |\n",
            "|    reward             | 1.1878312 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 0.39      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 89        |\n",
            "|    iterations         | 1400      |\n",
            "|    time_elapsed       | 77        |\n",
            "|    total_timesteps    | 7000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | 0.0135    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1399      |\n",
            "|    policy_loss        | 198       |\n",
            "|    reward             | 3.1746228 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 28        |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 89        |\n",
            "|    iterations         | 1500      |\n",
            "|    time_elapsed       | 83        |\n",
            "|    total_timesteps    | 7500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | 0.0193    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1499      |\n",
            "|    policy_loss        | 288       |\n",
            "|    reward             | 1.3676707 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 56.3      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 89         |\n",
            "|    iterations         | 1600       |\n",
            "|    time_elapsed       | 89         |\n",
            "|    total_timesteps    | 8000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1599       |\n",
            "|    policy_loss        | 191        |\n",
            "|    reward             | -1.4639732 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 27.4       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 90        |\n",
            "|    iterations         | 1700      |\n",
            "|    time_elapsed       | 94        |\n",
            "|    total_timesteps    | 8500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1699      |\n",
            "|    policy_loss        | -927      |\n",
            "|    reward             | 2.9474723 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 578       |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 89         |\n",
            "|    iterations         | 1800       |\n",
            "|    time_elapsed       | 100        |\n",
            "|    total_timesteps    | 9000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | 0.00166    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1799       |\n",
            "|    policy_loss        | 411        |\n",
            "|    reward             | -6.1446824 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 145        |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 89       |\n",
            "|    iterations         | 1900     |\n",
            "|    time_elapsed       | 105      |\n",
            "|    total_timesteps    | 9500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.2    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1899     |\n",
            "|    policy_loss        | -21.6    |\n",
            "|    reward             | 1.363894 |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 2.87     |\n",
            "------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 89          |\n",
            "|    iterations         | 2000        |\n",
            "|    time_elapsed       | 111         |\n",
            "|    total_timesteps    | 10000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.2       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1999        |\n",
            "|    policy_loss        | 71.7        |\n",
            "|    reward             | -0.22970784 |\n",
            "|    std                | 1           |\n",
            "|    value_loss         | 5.81        |\n",
            "---------------------------------------\n",
            "======a2c Validation from:  2022-01-03 to  2022-04-04\n",
            "a2c Sharpe Ratio:  -0.14964094241993825\n",
            "======ddpg Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ddpg/ddpg_189_1\n",
            "day: 3020, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 5578871.95\n",
            "total_reward: 4578871.95\n",
            "total_cost: 6412.75\n",
            "total_trades: 43848\n",
            "Sharpe: 0.892\n",
            "=================================\n",
            "======ddpg Validation from:  2022-01-03 to  2022-04-04\n",
            "ddpg Sharpe Ratio:  -0.14468602927524762\n",
            "======td3 Training========\n",
            "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.0001}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/td3/td3_189_1\n",
            "day: 3020, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 6425532.78\n",
            "total_reward: 5425532.78\n",
            "total_cost: 1722.84\n",
            "total_trades: 59909\n",
            "Sharpe: 1.017\n",
            "=================================\n",
            "======td3 Validation from:  2022-01-03 to  2022-04-04\n",
            "td3 Sharpe Ratio:  -0.11442242496728725\n",
            "======sac Training========\n",
            "{'batch_size': 64, 'buffer_size': 100000, 'learning_rate': 0.0001, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/sac/sac_189_1\n",
            "day: 3020, episode: 15\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 8124862.63\n",
            "total_reward: 7124862.63\n",
            "total_cost: 237765.81\n",
            "total_trades: 63551\n",
            "Sharpe: 1.071\n",
            "=================================\n",
            "======sac Validation from:  2022-01-03 to  2022-04-04\n",
            "sac Sharpe Ratio:  -0.24136303338325615\n",
            "======ppo Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ppo/ppo_189_1\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    fps             | 99        |\n",
            "|    iterations      | 1         |\n",
            "|    time_elapsed    | 20        |\n",
            "|    total_timesteps | 2048      |\n",
            "| train/             |           |\n",
            "|    reward          | 0.5211386 |\n",
            "----------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 95          |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 42          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019563863 |\n",
            "|    clip_fraction        | 0.224       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | 0.000872    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 3.56        |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0286     |\n",
            "|    reward               | -1.3335769  |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 10.2        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 95          |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 64          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013023874 |\n",
            "|    clip_fraction        | 0.149       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | -0.00524    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 32.3        |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0205     |\n",
            "|    reward               | -0.70423084 |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 49          |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 95          |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 85          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016133413 |\n",
            "|    clip_fraction        | 0.175       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | -0.00592    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 18.6        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0178     |\n",
            "|    reward               | -1.4647198  |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 53.1        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 95          |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 106         |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014833549 |\n",
            "|    clip_fraction        | 0.184       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.3       |\n",
            "|    explained_variance   | -0.0549     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 5.02        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0199     |\n",
            "|    reward               | -0.4377735  |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 12.2        |\n",
            "-----------------------------------------\n",
            "======ppo Validation from:  2022-01-03 to  2022-04-04\n",
            "ppo Sharpe Ratio:  -0.2547850420822254\n",
            "======Best Model Retraining from:  2010-01-01 to  2022-04-04\n",
            "======Trading from:  2022-04-04 to  2022-07-06\n",
            "============================================\n",
            "turbulence_threshold:  201.71766389369628\n",
            "======Model training from:  2010-01-01 to  2022-04-04\n",
            "======a2c Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/a2c/a2c_252_1\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 80         |\n",
            "|    iterations         | 100        |\n",
            "|    time_elapsed       | 6          |\n",
            "|    total_timesteps    | 500        |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | -0.368     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 99         |\n",
            "|    policy_loss        | -49.3      |\n",
            "|    reward             | -0.1616889 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 1.9        |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 86        |\n",
            "|    iterations         | 200       |\n",
            "|    time_elapsed       | 11        |\n",
            "|    total_timesteps    | 1000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | -0.0538   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 199       |\n",
            "|    policy_loss        | -53.6     |\n",
            "|    reward             | 1.5870696 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 5.6       |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 84         |\n",
            "|    iterations         | 300        |\n",
            "|    time_elapsed       | 17         |\n",
            "|    total_timesteps    | 1500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | 0.088      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 299        |\n",
            "|    policy_loss        | -13.9      |\n",
            "|    reward             | -2.2240775 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 4.12       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 86       |\n",
            "|    iterations         | 400      |\n",
            "|    time_elapsed       | 23       |\n",
            "|    total_timesteps    | 2000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.2    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 399      |\n",
            "|    policy_loss        | 42.6     |\n",
            "|    reward             | 2.902299 |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 14       |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 85         |\n",
            "|    iterations         | 500        |\n",
            "|    time_elapsed       | 29         |\n",
            "|    total_timesteps    | 2500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 499        |\n",
            "|    policy_loss        | -158       |\n",
            "|    reward             | -1.7140722 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 16         |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 86         |\n",
            "|    iterations         | 600        |\n",
            "|    time_elapsed       | 34         |\n",
            "|    total_timesteps    | 3000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 599        |\n",
            "|    policy_loss        | -245       |\n",
            "|    reward             | 15.5455885 |\n",
            "|    std                | 0.999      |\n",
            "|    value_loss         | 104        |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 85        |\n",
            "|    iterations         | 700       |\n",
            "|    time_elapsed       | 40        |\n",
            "|    total_timesteps    | 3500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 699       |\n",
            "|    policy_loss        | -149      |\n",
            "|    reward             | 1.2147838 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 17.8      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 86        |\n",
            "|    iterations         | 800       |\n",
            "|    time_elapsed       | 46        |\n",
            "|    total_timesteps    | 4000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 799       |\n",
            "|    policy_loss        | -167      |\n",
            "|    reward             | 1.3805329 |\n",
            "|    std                | 0.999     |\n",
            "|    value_loss         | 19.8      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 85         |\n",
            "|    iterations         | 900        |\n",
            "|    time_elapsed       | 52         |\n",
            "|    total_timesteps    | 4500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | -0.000948  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 899        |\n",
            "|    policy_loss        | 77.8       |\n",
            "|    reward             | -1.2849385 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 5.46       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 86        |\n",
            "|    iterations         | 1000      |\n",
            "|    time_elapsed       | 57        |\n",
            "|    total_timesteps    | 5000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 999       |\n",
            "|    policy_loss        | 64.1      |\n",
            "|    reward             | 4.2407904 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 3.73      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 86         |\n",
            "|    iterations         | 1100       |\n",
            "|    time_elapsed       | 63         |\n",
            "|    total_timesteps    | 5500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1099       |\n",
            "|    policy_loss        | -330       |\n",
            "|    reward             | -0.9968973 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 88.5       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 86         |\n",
            "|    iterations         | 1200       |\n",
            "|    time_elapsed       | 68         |\n",
            "|    total_timesteps    | 6000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1199       |\n",
            "|    policy_loss        | -84.8      |\n",
            "|    reward             | -2.5300012 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 8.07       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 87         |\n",
            "|    iterations         | 1300       |\n",
            "|    time_elapsed       | 74         |\n",
            "|    total_timesteps    | 6500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | 0.0485     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1299       |\n",
            "|    policy_loss        | 53.6       |\n",
            "|    reward             | 0.40684488 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 1.74       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 87        |\n",
            "|    iterations         | 1400      |\n",
            "|    time_elapsed       | 80        |\n",
            "|    total_timesteps    | 7000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1399      |\n",
            "|    policy_loss        | -62.3     |\n",
            "|    reward             | 2.0041661 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 5.82      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 87         |\n",
            "|    iterations         | 1500       |\n",
            "|    time_elapsed       | 85         |\n",
            "|    total_timesteps    | 7500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | -0.0839    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1499       |\n",
            "|    policy_loss        | -93.2      |\n",
            "|    reward             | 0.72117394 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 5.88       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 87         |\n",
            "|    iterations         | 1600       |\n",
            "|    time_elapsed       | 91         |\n",
            "|    total_timesteps    | 8000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | -0.16      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1599       |\n",
            "|    policy_loss        | 206        |\n",
            "|    reward             | -1.2223222 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 31.8       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 87        |\n",
            "|    iterations         | 1700      |\n",
            "|    time_elapsed       | 96        |\n",
            "|    total_timesteps    | 8500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1699      |\n",
            "|    policy_loss        | 225       |\n",
            "|    reward             | 4.8159285 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 46.5      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 87          |\n",
            "|    iterations         | 1800        |\n",
            "|    time_elapsed       | 103         |\n",
            "|    total_timesteps    | 9000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.2       |\n",
            "|    explained_variance | 0.038       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1799        |\n",
            "|    policy_loss        | 331         |\n",
            "|    reward             | 0.052169636 |\n",
            "|    std                | 1           |\n",
            "|    value_loss         | 70.3        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 87         |\n",
            "|    iterations         | 1900       |\n",
            "|    time_elapsed       | 108        |\n",
            "|    total_timesteps    | 9500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | 0.0665     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1899       |\n",
            "|    policy_loss        | -76.1      |\n",
            "|    reward             | 0.11070059 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 4.18       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 87         |\n",
            "|    iterations         | 2000       |\n",
            "|    time_elapsed       | 114        |\n",
            "|    total_timesteps    | 10000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1999       |\n",
            "|    policy_loss        | -31.8      |\n",
            "|    reward             | -0.9117036 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 0.734      |\n",
            "--------------------------------------\n",
            "======a2c Validation from:  2022-04-04 to  2022-07-06\n",
            "a2c Sharpe Ratio:  -0.2940200773845241\n",
            "======ddpg Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ddpg/ddpg_252_1\n",
            "day: 3083, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 4866008.60\n",
            "total_reward: 3866008.60\n",
            "total_cost: 6521.41\n",
            "total_trades: 41857\n",
            "Sharpe: 0.891\n",
            "=================================\n",
            "======ddpg Validation from:  2022-04-04 to  2022-07-06\n",
            "ddpg Sharpe Ratio:  -0.1726751932596474\n",
            "======td3 Training========\n",
            "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.0001}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/td3/td3_252_1\n",
            "day: 3083, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 4361118.07\n",
            "total_reward: 3361118.07\n",
            "total_cost: 1233.55\n",
            "total_trades: 56925\n",
            "Sharpe: 0.764\n",
            "=================================\n",
            "======td3 Validation from:  2022-04-04 to  2022-07-06\n",
            "td3 Sharpe Ratio:  -0.20262365833027873\n",
            "======sac Training========\n",
            "{'batch_size': 64, 'buffer_size': 100000, 'learning_rate': 0.0001, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/sac/sac_252_1\n",
            "day: 3083, episode: 15\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 4502151.61\n",
            "total_reward: 3502151.61\n",
            "total_cost: 114501.78\n",
            "total_trades: 51440\n",
            "Sharpe: 0.782\n",
            "=================================\n",
            "======sac Validation from:  2022-04-04 to  2022-07-06\n",
            "sac Sharpe Ratio:  -0.10385609512117487\n",
            "======ppo Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ppo/ppo_252_1\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    fps             | 98         |\n",
            "|    iterations      | 1          |\n",
            "|    time_elapsed    | 20         |\n",
            "|    total_timesteps | 2048       |\n",
            "| train/             |            |\n",
            "|    reward          | 0.18787862 |\n",
            "-----------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 97          |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 41          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018454969 |\n",
            "|    clip_fraction        | 0.214       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | -0.011      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 5.36        |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0296     |\n",
            "|    reward               | 0.103744656 |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 9.78        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 97          |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 62          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015241235 |\n",
            "|    clip_fraction        | 0.15        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.3       |\n",
            "|    explained_variance   | -0.00516    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 28.6        |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0217     |\n",
            "|    reward               | -7.9079633  |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 53.8        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 97           |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 84           |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0153032765 |\n",
            "|    clip_fraction        | 0.137        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -41.3        |\n",
            "|    explained_variance   | -0.00748     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 64.5         |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.0169      |\n",
            "|    reward               | -1.068388    |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 75.9         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 96          |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 106         |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015482018 |\n",
            "|    clip_fraction        | 0.176       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.3       |\n",
            "|    explained_variance   | -0.123      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 6.12        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0263     |\n",
            "|    reward               | -0.52738357 |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 11.9        |\n",
            "-----------------------------------------\n",
            "======ppo Validation from:  2022-04-04 to  2022-07-06\n",
            "ppo Sharpe Ratio:  -0.2999979024447023\n",
            "======Best Model Retraining from:  2010-01-01 to  2022-07-06\n",
            "======Trading from:  2022-07-06 to  2022-10-04\n",
            "============================================\n",
            "turbulence_threshold:  201.71766389369628\n",
            "======Model training from:  2010-01-01 to  2022-07-06\n",
            "======a2c Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/a2c/a2c_315_1\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 88          |\n",
            "|    iterations         | 100         |\n",
            "|    time_elapsed       | 5           |\n",
            "|    total_timesteps    | 500         |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.3       |\n",
            "|    explained_variance | -0.0146     |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 99          |\n",
            "|    policy_loss        | 0.0471      |\n",
            "|    reward             | -0.35088786 |\n",
            "|    std                | 1           |\n",
            "|    value_loss         | 0.698       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 89        |\n",
            "|    iterations         | 200       |\n",
            "|    time_elapsed       | 11        |\n",
            "|    total_timesteps    | 1000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 199       |\n",
            "|    policy_loss        | -78.6     |\n",
            "|    reward             | 0.1086251 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 4.73      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 91        |\n",
            "|    iterations         | 300       |\n",
            "|    time_elapsed       | 16        |\n",
            "|    total_timesteps    | 1500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 299       |\n",
            "|    policy_loss        | 20.1      |\n",
            "|    reward             | -4.528595 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 3.89      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 89         |\n",
            "|    iterations         | 400        |\n",
            "|    time_elapsed       | 22         |\n",
            "|    total_timesteps    | 2000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 399        |\n",
            "|    policy_loss        | -42.1      |\n",
            "|    reward             | 0.81548464 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 2.75       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 90         |\n",
            "|    iterations         | 500        |\n",
            "|    time_elapsed       | 27         |\n",
            "|    total_timesteps    | 2500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 499        |\n",
            "|    policy_loss        | 0.981      |\n",
            "|    reward             | -1.1102992 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 5.55       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 89        |\n",
            "|    iterations         | 600       |\n",
            "|    time_elapsed       | 33        |\n",
            "|    total_timesteps    | 3000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.1     |\n",
            "|    explained_variance | -0.00823  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 599       |\n",
            "|    policy_loss        | -31       |\n",
            "|    reward             | -0.627312 |\n",
            "|    std                | 0.999     |\n",
            "|    value_loss         | 5.48      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 90        |\n",
            "|    iterations         | 700       |\n",
            "|    time_elapsed       | 38        |\n",
            "|    total_timesteps    | 3500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | -0.0713   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 699       |\n",
            "|    policy_loss        | -39.8     |\n",
            "|    reward             | 0.4477165 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 1.35      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 89          |\n",
            "|    iterations         | 800         |\n",
            "|    time_elapsed       | 44          |\n",
            "|    total_timesteps    | 4000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.1       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 799         |\n",
            "|    policy_loss        | -17.2       |\n",
            "|    reward             | -0.19950393 |\n",
            "|    std                | 1           |\n",
            "|    value_loss         | 0.587       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 90         |\n",
            "|    iterations         | 900        |\n",
            "|    time_elapsed       | 49         |\n",
            "|    total_timesteps    | 4500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | 0.00645    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 899        |\n",
            "|    policy_loss        | 15.8       |\n",
            "|    reward             | 0.15722074 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 1.87       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 89        |\n",
            "|    iterations         | 1000      |\n",
            "|    time_elapsed       | 55        |\n",
            "|    total_timesteps    | 5000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 999       |\n",
            "|    policy_loss        | -59.3     |\n",
            "|    reward             | 1.2229588 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 3.95      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 90        |\n",
            "|    iterations         | 1100      |\n",
            "|    time_elapsed       | 60        |\n",
            "|    total_timesteps    | 5500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1099      |\n",
            "|    policy_loss        | -54.2     |\n",
            "|    reward             | 2.0828733 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 12.5      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 89        |\n",
            "|    iterations         | 1200      |\n",
            "|    time_elapsed       | 66        |\n",
            "|    total_timesteps    | 6000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | 0.0223    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1199      |\n",
            "|    policy_loss        | -7.34     |\n",
            "|    reward             | 6.6588287 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 5.51      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 90        |\n",
            "|    iterations         | 1300      |\n",
            "|    time_elapsed       | 72        |\n",
            "|    total_timesteps    | 6500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1299      |\n",
            "|    policy_loss        | -0.921    |\n",
            "|    reward             | -1.221114 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 0.41      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 89         |\n",
            "|    iterations         | 1400       |\n",
            "|    time_elapsed       | 78         |\n",
            "|    total_timesteps    | 7000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.1      |\n",
            "|    explained_variance | -0.0369    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1399       |\n",
            "|    policy_loss        | -124       |\n",
            "|    reward             | -1.2872689 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 11.9       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 89        |\n",
            "|    iterations         | 1500      |\n",
            "|    time_elapsed       | 83        |\n",
            "|    total_timesteps    | 7500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1499      |\n",
            "|    policy_loss        | -119      |\n",
            "|    reward             | 4.0148807 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 11.6      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 90          |\n",
            "|    iterations         | 1600        |\n",
            "|    time_elapsed       | 88          |\n",
            "|    total_timesteps    | 8000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.2       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1599        |\n",
            "|    policy_loss        | -43.1       |\n",
            "|    reward             | -0.74472225 |\n",
            "|    std                | 1           |\n",
            "|    value_loss         | 4.18        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 89          |\n",
            "|    iterations         | 1700        |\n",
            "|    time_elapsed       | 94          |\n",
            "|    total_timesteps    | 8500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.2       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1699        |\n",
            "|    policy_loss        | 260         |\n",
            "|    reward             | -0.93637145 |\n",
            "|    std                | 1           |\n",
            "|    value_loss         | 47.8        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 90        |\n",
            "|    iterations         | 1800      |\n",
            "|    time_elapsed       | 99        |\n",
            "|    total_timesteps    | 9000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | 1.79e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1799      |\n",
            "|    policy_loss        | 11.2      |\n",
            "|    reward             | 0.1899164 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 102       |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 89          |\n",
            "|    iterations         | 1900        |\n",
            "|    time_elapsed       | 105         |\n",
            "|    total_timesteps    | 9500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.2       |\n",
            "|    explained_variance | 0.234       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1899        |\n",
            "|    policy_loss        | 39.1        |\n",
            "|    reward             | 0.075078934 |\n",
            "|    std                | 1           |\n",
            "|    value_loss         | 1.1         |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 90         |\n",
            "|    iterations         | 2000       |\n",
            "|    time_elapsed       | 110        |\n",
            "|    total_timesteps    | 10000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1999       |\n",
            "|    policy_loss        | 12.5       |\n",
            "|    reward             | -1.1419047 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 0.499      |\n",
            "--------------------------------------\n",
            "======a2c Validation from:  2022-07-06 to  2022-10-04\n",
            "a2c Sharpe Ratio:  0.01708700162640674\n",
            "======ddpg Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ddpg/ddpg_315_1\n",
            "day: 3146, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 6835111.12\n",
            "total_reward: 5835111.12\n",
            "total_cost: 6913.39\n",
            "total_trades: 36545\n",
            "Sharpe: 0.999\n",
            "=================================\n",
            "======ddpg Validation from:  2022-07-06 to  2022-10-04\n",
            "ddpg Sharpe Ratio:  -0.11320567126181347\n",
            "======td3 Training========\n",
            "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.0001}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/td3/td3_315_1\n",
            "day: 3146, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 4445949.58\n",
            "total_reward: 3445949.58\n",
            "total_cost: 999.00\n",
            "total_trades: 47169\n",
            "Sharpe: 0.714\n",
            "=================================\n",
            "======td3 Validation from:  2022-07-06 to  2022-10-04\n",
            "td3 Sharpe Ratio:  -0.07186767142310117\n",
            "======sac Training========\n",
            "{'batch_size': 64, 'buffer_size': 100000, 'learning_rate': 0.0001, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/sac/sac_315_1\n",
            "day: 3146, episode: 15\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 2503132.45\n",
            "total_reward: 1503132.45\n",
            "total_cost: 189651.97\n",
            "total_trades: 57940\n",
            "Sharpe: 0.502\n",
            "=================================\n",
            "======sac Validation from:  2022-07-06 to  2022-10-04\n",
            "sac Sharpe Ratio:  -0.11546244328882915\n",
            "======ppo Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ppo/ppo_315_1\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    fps             | 98         |\n",
            "|    iterations      | 1          |\n",
            "|    time_elapsed    | 20         |\n",
            "|    total_timesteps | 2048       |\n",
            "| train/             |            |\n",
            "|    reward          | 0.84917784 |\n",
            "-----------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 98          |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 41          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014497358 |\n",
            "|    clip_fraction        | 0.21        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | -0.00253    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 4.88        |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.024      |\n",
            "|    reward               | 3.1660416   |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 13.6        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 97         |\n",
            "|    iterations           | 3          |\n",
            "|    time_elapsed         | 63         |\n",
            "|    total_timesteps      | 6144       |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01694668 |\n",
            "|    clip_fraction        | 0.156      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -41.2      |\n",
            "|    explained_variance   | 0.00737    |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | 24.4       |\n",
            "|    n_updates            | 20         |\n",
            "|    policy_gradient_loss | -0.018     |\n",
            "|    reward               | 1.9450325  |\n",
            "|    std                  | 1          |\n",
            "|    value_loss           | 87.4       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 97         |\n",
            "|    iterations           | 4          |\n",
            "|    time_elapsed         | 84         |\n",
            "|    total_timesteps      | 8192       |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01571557 |\n",
            "|    clip_fraction        | 0.158      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -41.3      |\n",
            "|    explained_variance   | -0.00387   |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | 22.6       |\n",
            "|    n_updates            | 30         |\n",
            "|    policy_gradient_loss | -0.0175    |\n",
            "|    reward               | 0.6451514  |\n",
            "|    std                  | 1          |\n",
            "|    value_loss           | 40.9       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 96          |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 106         |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014744235 |\n",
            "|    clip_fraction        | 0.175       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.3       |\n",
            "|    explained_variance   | 0.0322      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 6.54        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0243     |\n",
            "|    reward               | 1.1373324   |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 20.7        |\n",
            "-----------------------------------------\n",
            "======ppo Validation from:  2022-07-06 to  2022-10-04\n",
            "ppo Sharpe Ratio:  -0.2780477932776141\n",
            "======Best Model Retraining from:  2010-01-01 to  2022-10-04\n",
            "======Trading from:  2022-10-04 to  2023-01-04\n",
            "============================================\n",
            "turbulence_threshold:  201.71766389369628\n",
            "======Model training from:  2010-01-01 to  2022-10-04\n",
            "======a2c Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/a2c/a2c_378_1\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 94         |\n",
            "|    iterations         | 100        |\n",
            "|    time_elapsed       | 5          |\n",
            "|    total_timesteps    | 500        |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | -0.652     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 99         |\n",
            "|    policy_loss        | -66.1      |\n",
            "|    reward             | -0.2634291 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 3.08       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 81         |\n",
            "|    iterations         | 200        |\n",
            "|    time_elapsed       | 12         |\n",
            "|    total_timesteps    | 1000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 199        |\n",
            "|    policy_loss        | -38.1      |\n",
            "|    reward             | -0.7067394 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 1.8        |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 85         |\n",
            "|    iterations         | 300        |\n",
            "|    time_elapsed       | 17         |\n",
            "|    total_timesteps    | 1500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | 0.071      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 299        |\n",
            "|    policy_loss        | -77.2      |\n",
            "|    reward             | -3.7560062 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 7.98       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 84        |\n",
            "|    iterations         | 400       |\n",
            "|    time_elapsed       | 23        |\n",
            "|    total_timesteps    | 2000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.3     |\n",
            "|    explained_variance | 0.0777    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 399       |\n",
            "|    policy_loss        | -13.7     |\n",
            "|    reward             | 0.8984405 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 4.14      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 86         |\n",
            "|    iterations         | 500        |\n",
            "|    time_elapsed       | 28         |\n",
            "|    total_timesteps    | 2500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 499        |\n",
            "|    policy_loss        | -159       |\n",
            "|    reward             | -2.1374087 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 14.9       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 86       |\n",
            "|    iterations         | 600      |\n",
            "|    time_elapsed       | 34       |\n",
            "|    total_timesteps    | 3000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.3    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 599      |\n",
            "|    policy_loss        | 246      |\n",
            "|    reward             | 9.744067 |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 65.2     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 87        |\n",
            "|    iterations         | 700       |\n",
            "|    time_elapsed       | 40        |\n",
            "|    total_timesteps    | 3500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.3     |\n",
            "|    explained_variance | -0.218    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 699       |\n",
            "|    policy_loss        | 31.3      |\n",
            "|    reward             | 1.3400972 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 0.615     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 86         |\n",
            "|    iterations         | 800        |\n",
            "|    time_elapsed       | 46         |\n",
            "|    total_timesteps    | 4000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | -0.0286    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 799        |\n",
            "|    policy_loss        | -21.1      |\n",
            "|    reward             | -1.8471618 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 0.306      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 87         |\n",
            "|    iterations         | 900        |\n",
            "|    time_elapsed       | 51         |\n",
            "|    total_timesteps    | 4500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 899        |\n",
            "|    policy_loss        | 124        |\n",
            "|    reward             | -1.2136776 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 8.97       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 86        |\n",
            "|    iterations         | 1000      |\n",
            "|    time_elapsed       | 57        |\n",
            "|    total_timesteps    | 5000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 999       |\n",
            "|    policy_loss        | 28.4      |\n",
            "|    reward             | 1.1518407 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 1.3       |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 87          |\n",
            "|    iterations         | 1100        |\n",
            "|    time_elapsed       | 62          |\n",
            "|    total_timesteps    | 5500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.3       |\n",
            "|    explained_variance | 0.032       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1099        |\n",
            "|    policy_loss        | -157        |\n",
            "|    reward             | -0.16976187 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 17          |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 87        |\n",
            "|    iterations         | 1200      |\n",
            "|    time_elapsed       | 68        |\n",
            "|    total_timesteps    | 6000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.3     |\n",
            "|    explained_variance | 0.0998    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1199      |\n",
            "|    policy_loss        | -230      |\n",
            "|    reward             | 3.0421467 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 35.3      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 87        |\n",
            "|    iterations         | 1300      |\n",
            "|    time_elapsed       | 74        |\n",
            "|    total_timesteps    | 6500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.4     |\n",
            "|    explained_variance | -0.0556   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1299      |\n",
            "|    policy_loss        | -48.3     |\n",
            "|    reward             | 1.7831565 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 4.46      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 87          |\n",
            "|    iterations         | 1400        |\n",
            "|    time_elapsed       | 80          |\n",
            "|    total_timesteps    | 7000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.4       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1399        |\n",
            "|    policy_loss        | 29.4        |\n",
            "|    reward             | -0.83008885 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 2.79        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 87         |\n",
            "|    iterations         | 1500       |\n",
            "|    time_elapsed       | 85         |\n",
            "|    total_timesteps    | 7500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1499       |\n",
            "|    policy_loss        | -214       |\n",
            "|    reward             | 0.32302094 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 28.7       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 87         |\n",
            "|    iterations         | 1600       |\n",
            "|    time_elapsed       | 91         |\n",
            "|    total_timesteps    | 8000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | 0.105      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1599       |\n",
            "|    policy_loss        | -97.5      |\n",
            "|    reward             | 0.49140903 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 7.88       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 87       |\n",
            "|    iterations         | 1700     |\n",
            "|    time_elapsed       | 96       |\n",
            "|    total_timesteps    | 8500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.3    |\n",
            "|    explained_variance | -0.00141 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1699     |\n",
            "|    policy_loss        | -53.6    |\n",
            "|    reward             | 4.926593 |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 17.8     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 88       |\n",
            "|    iterations         | 1800     |\n",
            "|    time_elapsed       | 102      |\n",
            "|    total_timesteps    | 9000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.3    |\n",
            "|    explained_variance | -0.014   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1799     |\n",
            "|    policy_loss        | 527      |\n",
            "|    reward             | -4.89703 |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 471      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 87       |\n",
            "|    iterations         | 1900     |\n",
            "|    time_elapsed       | 108      |\n",
            "|    total_timesteps    | 9500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.3    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1899     |\n",
            "|    policy_loss        | 537      |\n",
            "|    reward             | 7.032902 |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 206      |\n",
            "------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 88          |\n",
            "|    iterations         | 2000        |\n",
            "|    time_elapsed       | 113         |\n",
            "|    total_timesteps    | 10000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.2       |\n",
            "|    explained_variance | 4.77e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1999        |\n",
            "|    policy_loss        | -45.9       |\n",
            "|    reward             | -0.42734638 |\n",
            "|    std                | 1           |\n",
            "|    value_loss         | 1.46        |\n",
            "---------------------------------------\n",
            "======a2c Validation from:  2022-10-04 to  2023-01-04\n",
            "a2c Sharpe Ratio:  0.26898079473428765\n",
            "======ddpg Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ddpg/ddpg_378_1\n",
            "day: 3209, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 7428494.64\n",
            "total_reward: 6428494.64\n",
            "total_cost: 6737.77\n",
            "total_trades: 52634\n",
            "Sharpe: 0.940\n",
            "=================================\n",
            "======ddpg Validation from:  2022-10-04 to  2023-01-04\n",
            "ddpg Sharpe Ratio:  0.1976245442173695\n",
            "======td3 Training========\n",
            "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.0001}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/td3/td3_378_1\n"
          ]
        }
      ],
      "source": [
        "df_summary = ensemble_agent.run_ensemble_strategy(A2C_model_kwargs,\n",
        "                                                 PPO_model_kwargs,\n",
        "                                                 DDPG_model_kwargs,\n",
        "                                                 SAC_model_kwargs,\n",
        "                                                 TD3_model_kwargs,\n",
        "                                                 timesteps_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0qd8acMtj1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "ef19ff5d-9173-4268-e50b-6128cf9278f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Iter, Val Start, Val End, Model Used, A2C Sharpe, PPO Sharpe, DDPG Sharpe, SAC Sharpe, TD3 Sharpe]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-54aae13f-d8ce-4faf-8e3e-37668f9389e6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Iter</th>\n",
              "      <th>Val Start</th>\n",
              "      <th>Val End</th>\n",
              "      <th>Model Used</th>\n",
              "      <th>A2C Sharpe</th>\n",
              "      <th>PPO Sharpe</th>\n",
              "      <th>DDPG Sharpe</th>\n",
              "      <th>SAC Sharpe</th>\n",
              "      <th>TD3 Sharpe</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-54aae13f-d8ce-4faf-8e3e-37668f9389e6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-54aae13f-d8ce-4faf-8e3e-37668f9389e6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-54aae13f-d8ce-4faf-8e3e-37668f9389e6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_6bb85869-9394-439e-9d2c-2fa4c43b0b65\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_summary')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_6bb85869-9394-439e-9d2c-2fa4c43b0b65 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_summary');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_summary",
              "summary": "{\n  \"name\": \"df_summary\",\n  \"rows\": 0,\n  \"fields\": [\n    {\n      \"column\": \"Iter\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Val Start\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Val End\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Model Used\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"A2C Sharpe\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PPO Sharpe\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DDPG Sharpe\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SAC Sharpe\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TD3 Sharpe\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "df_summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6vvNSC6h1jZ"
      },
      "source": [
        "<a id='6'></a>\n",
        "# Part 7: Backtest Our Strategy\n",
        "Backtesting plays a key role in evaluating the performance of a trading strategy. Automated backtesting tool is preferred because it reduces the human error. We usually use the Quantopian pyfolio package to backtest our trading strategies. It is easy to use and consists of various individual plots that provide a comprehensive image of the performance of a trading strategy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4JKB--8tj1g"
      },
      "outputs": [],
      "source": [
        "unique_trade_date = processed[(processed.date > TEST_START_DATE)&(processed.date <= TEST_END_DATE)].date.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9mKF7GGtj1g",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "df_trade_date = pd.DataFrame({'datadate':unique_trade_date})\n",
        "\n",
        "df_account_value=pd.DataFrame()\n",
        "for i in range(rebalance_window+validation_window, len(unique_trade_date)+1,rebalance_window):\n",
        "    temp = pd.read_csv('results/account_value_trade_{}_{}.csv'.format('ensemble',i))\n",
        "    df_account_value = df_account_value.append(temp,ignore_index=True)\n",
        "sharpe=(252**0.5)*df_account_value.account_value.pct_change(1).mean()/df_account_value.account_value.pct_change(1).std()\n",
        "print('Sharpe Ratio: ',sharpe)\n",
        "df_account_value=df_account_value.join(df_trade_date[validation_window:].reset_index(drop=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oyosyW7_tj1g"
      },
      "outputs": [],
      "source": [
        "df_account_value.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLsRdw2Ctj1h"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "df_account_value.account_value.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lr2zX7ZxNyFQ"
      },
      "source": [
        "<a id='6.1'></a>\n",
        "## 7.1 BackTestStats\n",
        "pass in df_account_value, this information is stored in env class\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nzkr9yv-AdV_",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "print(\"==============Get Backtest Results===========\")\n",
        "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
        "\n",
        "perf_stats_all = backtest_stats(account_value=df_account_value)\n",
        "perf_stats_all = pd.DataFrame(perf_stats_all)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DiHhM1YkoCel"
      },
      "outputs": [],
      "source": [
        "#baseline stats\n",
        "print(\"==============Get Baseline Stats===========\")\n",
        "df_dji_ = get_baseline(\n",
        "        ticker=\"^DJI\",\n",
        "        start = df_account_value.loc[0,'date'],\n",
        "        end = df_account_value.loc[len(df_account_value)-1,'date'])\n",
        "\n",
        "stats = backtest_stats(df_dji_, value_col_name = 'close')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhJ9whD75WTs"
      },
      "outputs": [],
      "source": [
        "df_dji = pd.DataFrame()\n",
        "df_dji['date'] = df_account_value['date']\n",
        "df_dji['dji'] = df_dji_['close'] / df_dji_['close'][0] * env_kwargs[\"initial_amount\"]\n",
        "print(\"df_dji: \", df_dji)\n",
        "df_dji.to_csv(\"df_dji.csv\")\n",
        "df_dji = df_dji.set_index(df_dji.columns[0])\n",
        "print(\"df_dji: \", df_dji)\n",
        "df_dji.to_csv(\"df_dji+.csv\")\n",
        "\n",
        "df_account_value.to_csv('df_account_value.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9U6Suru3h1jc"
      },
      "source": [
        "<a id='6.2'></a>\n",
        "## 7.2 BackTestPlot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HggausPRoCem"
      },
      "outputs": [],
      "source": [
        "\n",
        "# print(\"==============Compare to DJIA===========\")\n",
        "# %matplotlib inline\n",
        "# # S&P 500: ^GSPC\n",
        "# # Dow Jones Index: ^DJI\n",
        "# # NASDAQ 100: ^NDX\n",
        "# backtest_plot(df_account_value,\n",
        "#               baseline_ticker = '^DJI',\n",
        "#               baseline_start = df_account_value.loc[0,'date'],\n",
        "#               baseline_end = df_account_value.loc[len(df_account_value)-1,'date'])\n",
        "df.to_csv(\"df.csv\")\n",
        "df_result_ensemble = pd.DataFrame({'date': df_account_value['date'], 'ensemble':df_account_value['account_value']})\n",
        "df_result_ensemble = df_result_ensemble.set_index('date')\n",
        "\n",
        "print(\"df_result_ensemble.columns: \", df_result_ensemble.columns)\n",
        "\n",
        "print(\"df_trade_date: \", df_trade_date)\n",
        "# df_result_ensemble['date'] = df_trade_date['datadate']\n",
        "# df_result_ensemble['account_value'] = df_account_value['account_value']\n",
        "df_result_ensemble.to_csv(\"df_result_ensemble.csv\")\n",
        "print(\"df_result_ensemble: \", df_result_ensemble)\n",
        "print(\"==============Compare to DJIA===========\")\n",
        "result = pd.DataFrame()\n",
        "# result = pd.merge(result, df_result_ensemble, left_index=True, right_index=True)\n",
        "\n",
        "result = pd.merge(df_result_ensemble, df_dji, left_index=True, right_index=True)\n",
        "print(\"result: \", result)\n",
        "result.to_csv(\"result.csv\")\n",
        "result.columns = ['ensemble', 'dji']\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams[\"figure.figsize\"] = (15, 5)\n",
        "plt.figure()\n",
        "result.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBQx4bVQFi-a"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}